{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1502bfeb",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 14th of June 2023, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "* I (Benny) will visit the exam room at around 10:30 to see if there are any questions.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b708db5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"0019-BYZ\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fcf1c7",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "140af589",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "A courier company operates a fleet of delivery trucks that make deliveries to different parts of the city. The trucks are equipped with GPS tracking devices that record the location of each truck at regular intervals. The locations are divided into three regions: downtown, the suburbs, and the countryside. The following table shows the probabilities of a truck transitioning between these regions at each time step:\n",
    "\n",
    "| Current region | Probability of transitioning to downtown | Probability of transitioning to the suburbs | Probability of transitioning to the countryside |\n",
    "|----------------|--------------------------------------------|-----------------------------------------------|------------------------------------------------|\n",
    "| Downtown       | 0.3                                      | 0.4                                           | 0.3                                            |\n",
    "| Suburbs        | 0.2                                      | 0.5                                           | 0.3                                            |\n",
    "| Countryside    | 0.4                                      | 0.3                                           | 0.3                                            |\n",
    "\n",
    "1. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region after two time steps? [2p]\n",
    "2. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region **the first time** after two time steps? [2p]\n",
    "3. Is this Markov chain irreducible? Explain your answer. [3p]\n",
    "4. What is the stationary distribution? [3p]\n",
    "5. Advanced question: What is the expected number of steps until the first time one enters the suburbs region having started in the downtown region. Hint: to get within 1 decimal point, it is enough to compute the probabilities for hitting times below 30. Motivate your answer in detail [4p]. You could also solve this question by simulation, but this gives you a maximum of [2p].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "510f5fc8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Fill in the answer to part 1 below\n",
    "problem1_p1 = 0.2 * 0.3 + 0.2* 0.5 + 0.4 * 0.3\n",
    "problem1_p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a8ca879",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "#sub->sub->sub->downtown\n",
    "#sub->sub->countryside->downtown\n",
    "#sub->countryside -> countryside -> downtown\n",
    "#sub->countryside ->  sub -> downtown\n",
    "# Fill in the answer to part 2 below\n",
    "problem1_p2 = 0.5* 0.2 + 0.3 * 0.4\n",
    "#problem1_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4468088",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Fill in the answer to part 3 below as a boolean\n",
    "problem1_irreducible = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edf617c3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Part 3\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 3 below this line.\n",
    "I think this Markov chian is irreducible. Because every status can transfer other status. For example, Suburbs -> Downtown -> Suburbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1946e9d",
   "metadata": {},
   "source": [
    "### Markov Chain Transition Probabilities\n",
    "\n",
    "| Current Region | Probability of Transitioning to Downtown | Probability of Transitioning to the Suburbs | Probability of Transitioning to the Countryside |\n",
    "|----------------|-----------------------------------------|--------------------------------------------|-------------------------------------------------|\n",
    "| Downtown       | 0.3                                     | 0.4                                        | 0.3                                             |\n",
    "| Suburbs        | 0.2                                     | 0.5                                        | 0.3                                             |\n",
    "| Countryside    | 0.4                                     | 0.3                                        | 0.3                                             |\n",
    "\n",
    "### Irreducibility Analysis\n",
    "\n",
    "The Markov chain is **irreducible**. This conclusion is drawn based on the following observations:\n",
    "\n",
    "- **From Downtown:**\n",
    "  - To Downtown: 0.3\n",
    "  - To Suburbs: 0.4\n",
    "  - To Countryside: 0.3\n",
    "- **From Suburbs:**\n",
    "  - To Downtown: 0.2\n",
    "  - To Suburbs: 0.5\n",
    "  - To Countryside: 0.3\n",
    "- **From Countryside:**\n",
    "  - To Downtown: 0.4\n",
    "  - To Suburbs: 0.3\n",
    "  - To Countryside: 0.3\n",
    "\n",
    "Since there is a non-zero probability of transitioning from each state to every other state, either directly or through a combination of states, this Markov chain is considered irreducible. Each state communicates with every other state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1404e5f5",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28888889, 0.41111111, 0.3       ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 4\n",
    "\n",
    "# Fill in the answer to part 4 below\n",
    "# the answer should be a numpy array of length 3\n",
    "# make sure that the entries sums to 1!\n",
    "#define vector x xP = x then x is correct answer.\n",
    "#answerpart4 = np.linalg.solve(x,P)\n",
    "P = np.array([[0.3,0.4,0.3],\n",
    "              [0.2,0.5,0.3],\n",
    "              [0.4,0.3,0.3]])\n",
    "\n",
    "evals,evecs = np.linalg.eig(P.T)\n",
    "problem1_stationary = np.real(evecs[:,0] / evecs[:,0].sum()) \n",
    "problem1_stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ebfa71e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "# Fill in the answer to part 5 below\n",
    "# That is, the expected number of steps\n",
    "# same autograded assignment 2\n",
    "# Part 5\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "P = {\n",
    "    'D': {'D': 0.3, 'S': 0.4, 'C': 0.3},\n",
    "    'S': {'D': 0.2, 'S': 0.5, 'C': 0.3},\n",
    "    'C': {'D': 0.4, 'S': 0.3, 'C': 0.3}\n",
    "}\n",
    "\n",
    "E = {'S': 0.0, 'C': 0.0}\n",
    "max_steps = 30\n",
    "memo = {'S': {}, 'C': {}}\n",
    "def expected_steps(start_region, steps):\n",
    "    if steps == max_steps:\n",
    "        return 0\n",
    "    if steps in memo[start_region]:\n",
    "        return memo[start_region][steps]\n",
    "    \n",
    "    exp_steps = P[start_region]['D']\n",
    "    for region, prob in P[start_region].items():\n",
    "        if region != 'D':  \n",
    "            exp_steps += prob * (1 + expected_steps(region, steps + 1))\n",
    "    \n",
    "    memo[start_region][steps] = exp_steps\n",
    "    return exp_steps\n",
    "\n",
    "expected_number_of_steps = expected_steps('S', 0)\n",
    "expected_number_of_steps = round(expected_number_of_steps,1)\n",
    "# Fill in the answer to part 5 below\n",
    "# That is, the expected number of steps as a decimal number\n",
    "problem1_ET = expected_number_of_steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abb77a62",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Part 5\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 5 below this line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3612800",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "006eb1b6",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "You are given the \"Abalone\" dataset found in `data/abalone.csv`, which contains physical measurements of abalone (a type of sea shells) and the age of the abalone measured in **rings** (the number of rings in the shell) [https://en.wikipedia.org/wiki/Abalone](https://en.wikipedia.org/wiki/Abalone). Your task is to train a `linear regression` model to predict the age (Rings) of an abalone based on its physical measurements.\n",
    "\n",
    "To evaluate your model, you will split the dataset into a training set and a testing set. You will use the training set to train your model, and the testing set to evaluate its performance.\n",
    "\n",
    "1. Load the data into a pandas dataframe `problem2_df`. Based on the column names, figure out what are the features and the target and fill in the answer in the correct cell below. [2p]\n",
    "2. Split the data into train and test. [2p]\n",
    "3. Train the model. [1p]\n",
    "4. On the test set, evaluate the model by computing the mean absolute error and plot the empirical distribution function of the residual with confidence bands (i.e. using the DKW inequality and 95% confidence). Hint: you can use the function `plotEDF,makeEDF` combo from `Utils.py` that we have used numerous times, which also contains the option to have confidence bands. [3p]\n",
    "5. Provide a scatter plot where the x-axis corresponds to the predicted value and the y-axis is the true value, do this over the test set. [2p]\n",
    "6. Reason about the performance, for instance, is the value of the mean absolute error good/bad and what do you think about the scatter plot in point 5? [3p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67ad9ee5",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/abalone.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m  \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/abalone.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#no data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m problem2_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/abalone.csv'"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "# Let problem2_df be the pandas dataframe that contains the data from the file\n",
    "# data/abalone.csv\n",
    "import numpy as np\n",
    "import pandas  as pd\n",
    "filepath = \"data/abalone.csv\" #no data\n",
    "problem2_df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6e330",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Fill in the features as a list of strings of the names of the columns\n",
    "\n",
    "problem2_features = [\"XXX\"]\n",
    "\n",
    "# Fill in the target as a string with the correct column name\n",
    "\n",
    "problem2_target = \"XXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614db4e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "\n",
    "# Split the data into train and test using train_test_split\n",
    "# keep the train size as 0.8 and use random_state=42\n",
    "problem2_X_train,problem2_X_test,problem2_y_train,problem2_y_test = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10349b69",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Include the necessary imports\n",
    "\n",
    "# Initialize your linear regression model\n",
    "problem2_model = XXX\n",
    "\n",
    "# Train your model on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf8286",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# Evaluate the model by computing the mean absolute error \n",
    "problem2_mae = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f247ee5e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# Write the code to plot the empirical distribution function of the residual\n",
    "# with confidence bands with 95% confidence in this cell\n",
    "\n",
    "# from Utils import makeEDF,plotEDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76a549",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "# Write the code below to produce the scatter plot for part 5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6968726",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "## Part 6\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 6 below this line.\n",
    "\n",
    "#### Discussion on the value of the MAE\n",
    "\n",
    "#### Discussion on the predicted vs. true scatterplot\n",
    "\n",
    "#### Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065a99f",
   "metadata": {},
   "source": [
    "## Part 6\n",
    "\n",
    "### Discussion on the value of the MAE\n",
    "\n",
    "The Mean Absolute Error (MAE) is a key metric in evaluating regression models, reflecting the average magnitude of errors in predictions. When considering the MAE:\n",
    "\n",
    "- **Magnitude of MAE**: Assess how significant the MAE is in relation to the target variable's range or standard deviation.\n",
    "- **Baseline Comparison**: Contextualize the MAE by comparing it to a baseline model, such as one predicting the mean or median.\n",
    "- **Error Distribution**: Remember, the MAE treats all errors equally. It's often used alongside other metrics like Mean Squared Error (MSE) or R-squared for a more comprehensive evaluation.\n",
    "\n",
    "### Discussion on the predicted vs. true scatterplot\n",
    "\n",
    "A scatterplot of predicted versus true values offers visual insights into a model's performance:\n",
    "\n",
    "- **Linearity**: Points should ideally align with the y = x line. Deviations indicate prediction inaccuracies.\n",
    "- **Outliers**: Pay attention to points significantly far from this line, as they represent large errors.\n",
    "- **Homoscedasticity**: Check for consistent spread across all levels of predicted values. Varied spread suggests the model performs differently across the target variable's range.\n",
    "\n",
    "### General Discussion\n",
    "\n",
    "Integrate insights from both the MAE and the scatterplot analysis:\n",
    "\n",
    "- Reflect on how these findings might guide model improvements, such as through feature engineering, model selection, or tuning.\n",
    "- Consider the practical implications of your model's accuracy for its intended application.\n",
    "- Suggest potential next steps based on your analysis, possibly including further validation or exploration of alternative modeling approaches.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81cb13",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "748f51f0",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "A healthcare organization is interested in understanding the relationship between the number of visits to the doctors office and certain patient characteristics. \n",
    "They have collected data on the number of visits for a sample of patients and have included the following variables\n",
    "\n",
    "* ofp : number of physician office visits\n",
    "* ofnp : number of nonphysician office visits\n",
    "* opp : number of physician outpatient visits\n",
    "* opnp : number of nonphysician outpatient visits\n",
    "* emr : number of emergency room visits\n",
    "* hosp : number of hospitalizations\n",
    "* exclhlth : the person is of excellent health (self-perceived)\n",
    "* poorhealth : the person is of poor health (self-perceived)\n",
    "* numchron : number of chronic conditions\n",
    "* adldiff : the person has a condition that limits activities of daily living ?\n",
    "* noreast : the person is from the north east region\n",
    "* midwest : the person is from the midwest region\n",
    "* west : the person is from the west region\n",
    "* age : age in years (divided by 10)\n",
    "* male : is the person male ?\n",
    "* married : is the person married ?\n",
    "* school : number of years of education\n",
    "* faminc : family income in 10000$\n",
    "* employed : is the person employed ?\n",
    "* privins : is the person covered by private health insurance?\n",
    "* medicaid : is the person covered by medicaid ?\n",
    "\n",
    "Decide which patient features are resonable to use to predict the target \"number of physician office visits\". Hint: should we really use the \"ofnp\" etc variables?\n",
    "\n",
    "Since the target variable is counts, a reasonable loss function is to consider the target variable as Poisson distributed where the parameter follows $\\lambda = \\exp(\\alpha \\cdot x + \\beta)$ where $\\alpha$ is a vector (slope) and $\\beta$ is a number (intercept). That is, the parameter is the exponential of a linear function. The reason we chose this as our parameter, is that it is always positive which is when the Poisson distribution is defined. To be specific we make the following assumption about our conditional density of $Y \\mid X$,\n",
    "$$\n",
    "    f_{Y \\mid X} (y,x) = \\frac{\\lambda^{y} e^{-\\lambda}}{y !}, \\quad \\lambda(x) = \\exp(\\alpha \\cdot x + \\beta).\n",
    "$$\n",
    "\n",
    "Recall from the lecture notes, (4.2) that in this case we should consider the log-loss (entropy) and that according to (4.2.1 Maximum Likelihood and regression) we can consider the conditional log-likelihood. Follow the steps of Example 1 and Example 2 in section (4.2) to derive the loss that needs to be minimized.\n",
    "\n",
    "Hint: when taking the log of the conditional density you will find that the term that contains the $y!$ does not depend on $\\lambda$ and as such does not depend on $\\alpha,\\beta$, it can thus be discarded. This will be essential due to numerical issues with factorials.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Load the file `data/visits_clean.csv` into the pandas dataframe `problem3_df`. Decide what should be features and target, give motivations for your choices. [3p]\n",
    "2. Create the `problem3_X` and the `problem3_y` as numpy arrays with `problem3_X` being the features and `problem3_y` being the target. Do the standard train-test split with 80% training data and 20% testing data. Store these in the variables defined in the cells. [3p]\n",
    "3. Implement $loss$ inside the class `PoissonRegression` by writing down the loss to be minimized, I have provided a formula for the $\\lambda$ that you can use. [2p]\n",
    "4. Now use the `PoissonRegression` class to train a Poisson regression model on the training data. [2p]\n",
    "5. Come up with a reasonable metric to evaluate your model on the test data, compute it and write down a justification of this. Also, interpret your result and compare it to something naive. [3p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d71cb526",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  0.,  0., ...,  1.,  1.,  0.],\n",
       "       [ 1.,  0.,  2., ...,  0.,  1.,  0.],\n",
       "       [13.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [10.,  0., 20., ...,  0.,  1.,  0.],\n",
       "       [16.,  1.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Let problem3_df be the pandas dataframe that contains the data from the file\n",
    "# data/visits_clean.csv\n",
    "import csv\n",
    "import numpy as np\n",
    "header_max = []\n",
    "data_max = []\n",
    "\n",
    "csv_file_path = 'data/visits_clean.csv' #if you want to upload please change the data path , data/visits_clean.csv\n",
    "\n",
    "with open(csv_file_path, 'r', newline='') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter = ' ')\n",
    "    \n",
    "    header_max = next(csvreader)\n",
    "    \n",
    "data_max=np.genfromtxt(csv_file_path,dtype=float,delimiter=\" \",skip_header=1)\n",
    "# The autograder does not accept pandas as a solution to this problem.\n",
    "# data/visits_clean.csv\n",
    "problem3_df_header = header_max #List of strings\n",
    "problem3_df_data = np.array(data_max) #A numpy array of shape n_samples n_columns\n",
    "problem3_df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9674f37",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ofnp',\n",
       " 'opp',\n",
       " 'opnp',\n",
       " 'emr',\n",
       " 'hosp',\n",
       " 'exclhlth',\n",
       " 'poorhlth',\n",
       " 'numchron',\n",
       " 'adladiff',\n",
       " 'noreast',\n",
       " 'midwest',\n",
       " 'west',\n",
       " 'age',\n",
       " 'male',\n",
       " 'married',\n",
       " 'school',\n",
       " 'faminc',\n",
       " 'employed',\n",
       " 'privins',\n",
       " 'medicaid']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1\n",
    "\n",
    "# Fill in the features as a list of strings of the names of the columns\n",
    "\n",
    "problem3_features = [\"ofnp\",\"opp\",\"opnp\",\"emr\",\"hosp\",\"exclhlth\",\"poorhlth\",\"numchron\",\"adladiff\",\"noreast\",\"midwest\",\"west\",\"age\",\"male\",\"married\",\"school\",\"faminc\",\"employed\",\"privins\",\"medicaid\"]\n",
    "# Fill in the target as a string with the correct column name\n",
    "\n",
    "problem3_target = \"ofp\"\n",
    "problem3_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "263a3bee",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "## Part 1\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 1 below this line.\n",
    "\n",
    "#### What features are reasonable?\n",
    "\n",
    "#### In regards to how much data we have, how many features do you think we should aim for?\n",
    "\n",
    "#### What other features would you like to have used but was not collected?\n",
    "\n",
    "#### Discussion\n",
    "\n",
    "What features are reasonable?\n",
    "To predict the number of physician office visits (ofp), it's essential to select features that are likely to influence this variable without being directly correlated to it in a way that would introduce redundancy or leakage. \n",
    "Based on the variables provided, the following features seem reasonable:\n",
    "exclhlth & poorhealth: Self-perceived health status can influence the frequency of physician visits. People who perceive their health as poor might visit doctors more often.\n",
    "numchron: The number of chronic conditions is directly related to healthcare needs, likely affecting physician visits.\n",
    "adldiff: If a person has difficulty with activities of daily living, this might indicate a higher need for medical attention.\n",
    "noreast, midwest, west: Geographic region can influence healthcare access and utilization patterns.\n",
    "age: Older individuals generally have more health issues and thus might visit physicians more frequently.\n",
    "male & married: Gender and marital status can influence healthcare-seeking behavior.\n",
    "school: Education level might correlate with health awareness and thus the frequency of physician visits.\n",
    "faminc: Family income can affect access to healthcare and willingness to seek medical help.\n",
    "employed: Employment status can influence health insurance coverage and ability to afford healthcare.\n",
    "privins & medicaid: Insurance coverage greatly affects healthcare utilization.\n",
    "Variables like ofnp, opp, opnp, emr, and hosp should not be used as they are other types of healthcare visits or hospitalizations, which could be consequences or causes of physician office visits, leading to data leakage.\n",
    "\n",
    "In regards to how much data we have, how many features do you think we should aim for?\n",
    "The number of features to include depends on the size of the dataset. Too many features relative to the number of observations can lead to overfitting, where the model learns noise rather than the underlying pattern. A general rule is to have significantly more observations than features. Without knowing the exact size of the dataset, it's challenging to specify an exact number of features, but a conservative approach would be advisable.\n",
    "\n",
    "What other features would you like to have used but was not collected?\n",
    "Additional useful features might include:\n",
    "\n",
    "Mental health status: Mental health can influence physical health and healthcare utilization.\n",
    "Lifestyle factors: Information on smoking, alcohol use, diet, and exercise could provide insights into health behaviors that affect the need for physician visits.\n",
    "Family medical history: Genetic predispositions to certain conditions could be relevant.\n",
    "Previous healthcare utilization: Data on past physician visits might help predict future behavior.\n",
    "\n",
    "Discussion\n",
    "The selection of features is a balance between capturing enough information to accurately predict physician office visits and avoiding overfitting or data leakage. The chosen features should provide a comprehensive view of a patient's health status, lifestyle, and socio-economic context, as these are all factors that can influence healthcare-seeking behavior.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d00cab8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(problem3_df_data)\n",
    "problem3_data = scaler.transform(problem3_df_data) \n",
    "\n",
    "\n",
    "problem2_X = problem3_data[[],1:]\n",
    "problem2_y = problem3_data[[],0]\n",
    "\n",
    "indices = np.arange(problem3_data.shape[0])\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_ratio=0.8\n",
    "total_samples=problem3_data.shape[0]\n",
    "train_samples=int(total_samples*train_ratio)\n",
    "\n",
    "problem3_X_train = problem3_data[indices[:train_samples],1:]\n",
    "problem3_y_train = problem3_data[indices[:train_samples],0]\n",
    "\n",
    "\n",
    "problem3_X_test = problem3_data[indices[train_samples:], 1:]\n",
    "problem3_y_test = problem3_data[indices[train_samples:], 0]\n",
    "\n",
    "# Replace 'XXX' with the actual variables\n",
    "problem3_X_train, problem3_X_test, problem3_y_train, problem3_y_test = problem3_X_train, problem3_X_test, problem3_y_train, problem3_y_test\n",
    "\n",
    "\n",
    "# Fill in your X and y below\n",
    "#problem3_X = pro3_data[[],1:]\n",
    "#problem3_y = pro3_data[[],0]\n",
    "# Split the data into train and test using train_test_split\n",
    "# keep the train size as 0.8 and use random_state=42\n",
    "#problem3_X_train, problem3_X_test, problem3_y_train, problem3_y_test = train_test_split(problem3_X,problem3_y,train_size = 0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "68e8c054",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Fill in the function loss below\n",
    "\n",
    "class PoissonRegression(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        # define the objective/cost/loss function we want to minimise\n",
    "        def loss(coeffs):\n",
    "            # The parameter lambda for the given X and the proposed values \n",
    "            # of the coefficients, here coeff[:-1] represent alpha \n",
    "            # and coeff[-1] represent beta\n",
    "            lam = np.exp(np.dot(X,coeffs[:-1])+coeffs[-1])\n",
    "            neg_log_likelihood = -np.sum(Y * np.log(lam) - lam)\n",
    "            # use the Y variable that is available here to define \n",
    "            # the loss function, return the value of the loss for \n",
    "            # this Y and for this parameter lam defined above\n",
    "            return neg_log_likelihood\n",
    "\n",
    "        #Use the loss above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        #this is prepared for you below\n",
    "\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1) # initial guess as 0\n",
    "        self.result = optimize.minimize(loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            return np.exp(np.dot(X,self.coeffs[:-1])+self.coeffs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e713dd9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 828.9207292295235\n",
      "       x: [ 2.085e+00 -5.845e-01 ...  2.552e-01 -3.587e+00]\n",
      "     nit: 346\n",
      "     jac: [-7.629e-06  7.629e-06 ...  7.629e-06  7.629e-06]\n",
      "    nfev: 15138\n",
      "    njev: 688\n"
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "# Initialize your PoissonRegression model\n",
    "problem3_model = PoissonRegression()\n",
    "\n",
    "# Fit your initialized model on the training data\n",
    "problem3_model.fit(problem3_X_train,problem3_y_train)\n",
    "\n",
    "# This is to make sure that everything went well, \n",
    "# check that success is True\n",
    "print(problem3_model.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4036ed4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "# Put the computed metric value in the variable below\n",
    "problem3_metric = XXX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9efd042d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "## Part 5\n",
    "\n",
    "Double click this cell to enter edit mode and write your answer for part 5 below this line.\n",
    "\n",
    "#### Discussion on reasonable metrics and discussion about the value of the metric\n",
    "\n",
    "#### Comparison with a naive model\n",
    "Discussion on Reasonable Metrics\n",
    "To evaluate the performance of the Poisson Regression model on the test data, it's crucial to choose a metric that aligns with the nature of the data and the model's objectives. The following metrics are considered reasonable:\n",
    "\n",
    "Mean Absolute Error (MAE): This measures the average magnitude of the errors in a set of predictions, without considering their direction. It's a straightforward metric and easy to interpret.\n",
    "\n",
    "Root Mean Squared Error (RMSE): RMSE is a quadratic scoring rule that measures the average magnitude of the error. It’s particularly useful when large errors are particularly undesirable.\n",
    "\n",
    "Poisson Deviance: Given the Poisson nature of the data, the Poisson deviance can be a more tailored metric. It measures how well the model predicts the counts compared to the observed counts.\n",
    "\n",
    "The choice of metric should reflect the specific needs of the healthcare organization. If they are more concerned with the accuracy of predictions, regardless of the magnitude of the errors, MAE might be more appropriate. If they want to penalize larger errors more severely, RMSE would be a better choice. If the focus is on fitting the count nature of the data, Poisson Deviance is the most appropriate.\n",
    "\n",
    "Comparison with a Naive Model\n",
    "A naive model could be one that always predicts the average number of physician office visits from the training data for all instances in the test data. This model does not take into account any features of the patients and provides a baseline against which to compare the performance of the Poisson Regression model.\n",
    "\n",
    "By comparing the performance metrics (like MAE, RMSE, or Poisson Deviance) of the Poisson Regression model with those of the naive model, we can understand the value added by using a more sophisticated approach. If the Poisson Regression model significantly outperforms the naive model, it implies that the features chosen and the modeling approach are effectively capturing the underlying patterns in the data. If the performance is similar or worse, it could suggest that the model is not adequately capturing the complexities of the data, or that the features selected are not as informative as anticipated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2022",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
