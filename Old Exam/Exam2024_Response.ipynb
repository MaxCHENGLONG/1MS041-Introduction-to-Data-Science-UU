{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c41c0e",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 4th of January 2024, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1134c",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"0019-BYZ\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb47f3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6459beb1",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_inversion` in order to produce samples from the below distribution using rejection sampling:\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-1}{e-1}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "2. [2p] Produce 100000 samples (**use fewer if it times-out and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. *(There is a timeout decorator on this function and if it takes more than 10 seconds to generate 100000 samples it will timeout and it will count as if you failed to generate.)*\n",
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2e^{x^2} x}{e-1} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n",
    "\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n",
    "\n",
    "5. [4p] Fill in the remaining part of the function `problem1_inversion_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123f6216",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:48.829548Z",
     "iopub.status.busy": "2024-01-12T09:45:48.829004Z",
     "iopub.status.idle": "2024-01-12T09:45:48.845001Z",
     "shell.execute_reply": "2024-01-12T09:45:48.843857Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 1\n",
    "\n",
    "from Utils import timeout\n",
    "import random\n",
    "@timeout()\n",
    "def problem1_inversion(n_samples=1):\n",
    "    # Distribution from part 1\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "    answer = [ ]\n",
    "    for t in range(n_samples):\n",
    "        y = random.random()\n",
    "        if y <= 0:\n",
    "            x = 0\n",
    "            answer.append(x)\n",
    "        elif y < 1 and y > 0:\n",
    "            x = (np.exp(y ** 2) - 1 )/(np.exp(1) - 1)\n",
    "            answer.append(x)\n",
    "        else:\n",
    "            x = 1\n",
    "            answer.apppend(x)\n",
    "    # Return a numpy array of length n_samples\n",
    "    return np.asarray(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9efd556f",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:48.849353Z",
     "iopub.status.busy": "2024-01-12T09:45:48.848679Z",
     "iopub.status.idle": "2024-01-12T09:45:51.734949Z",
     "shell.execute_reply": "2024-01-12T09:45:51.733804Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 2\n",
    "import numpy as np\n",
    "problem1_samples = problem1_inversion(100000)\n",
    "#print(problem1_samples)\n",
    "#problem1_samplesdist =np.array(problem1_samples)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.hist(problem1_samples)\n",
    "sns.distplot(problem1_samples, hist=True, kde=True, \n",
    "             bins=int(100000/1000), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'},\n",
    "             kde_kws={'linewidth': 4})\n",
    "plt.show()\n",
    "#problem1_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb6e9f6",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:51.739928Z",
     "iopub.status.busy": "2024-01-12T09:45:51.739402Z",
     "iopub.status.idle": "2024-01-12T09:45:52.281010Z",
     "shell.execute_reply": "2024-01-12T09:45:52.279926Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27489750104546934\n"
     ]
    }
   ],
   "source": [
    "# Part 3\n",
    "import math\n",
    "import numpy as np\n",
    "def MC(samples,n_samples): \n",
    "    integral_value = 0\n",
    "    for i in range(n_samples):\n",
    "        x = samples[i]\n",
    "        integral_value = integral_value + (1-0)*(math.sin(x) * 2 * np.exp(x**2)*x )/(np.exp(1) -1)\n",
    "    integral_value = integral_value/n_samples\n",
    "    return integral_value\n",
    "problem1_integral = MC(problem1_samples,len(problem1_samples))\n",
    "print(problem1_integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bfda81",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:52.284340Z",
     "iopub.status.busy": "2024-01-12T09:45:52.284007Z",
     "iopub.status.idle": "2024-01-12T09:45:52.293889Z",
     "shell.execute_reply": "2024-01-12T09:45:52.293107Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2661408288436799, 0.2747302170106147)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 4\n",
    "from numpy import *\n",
    "def hoeffding_interval(sample_mean, n, a, b, confidence_level=0.95):\n",
    "    epsilon = np.sqrt(np.log(2 / (1 - confidence_level)) / (2 * n))\n",
    "    return max(a, sample_mean - epsilon * (b - a)), min(b, sample_mean + epsilon * (b - a))\n",
    "problem1_samples_avg = np.mean(problem1_samples)\n",
    "n = len(problem1_samples)\n",
    "a = 0.0 \n",
    "b = 1.0\n",
    "problem1_interval = hoeffding_interval(problem1_samples_avg,n,a,b)\n",
    "problem1_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fadf367",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:52.297570Z",
     "iopub.status.busy": "2024-01-12T09:45:52.297242Z",
     "iopub.status.idle": "2024-01-12T09:45:52.303459Z",
     "shell.execute_reply": "2024-01-12T09:45:52.302721Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "import random\n",
    "import numpy as np\n",
    "def problem1_inversion_2(n_samples=1):\n",
    "    # Distribution from part 2\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "    samples = [ ]\n",
    "    for t in range(n_samples):\n",
    "        y = random.random()\n",
    "        if y <= 0:\n",
    "            x = 0\n",
    "            samples.append(x)\n",
    "        elif y > 0 and y < 1/20:\n",
    "            x = 20 * x * np.exp(20- 1/x )\n",
    "            samples.append(x)\n",
    "        else:\n",
    "            x = 1\n",
    "            samples.append(x)\n",
    "    # Return a numpy array of length n_samples\n",
    "    return np.asarray(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4783bc",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f15899c",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:52.307124Z",
     "iopub.status.busy": "2024-01-12T09:45:52.306370Z",
     "iopub.status.idle": "2024-01-12T09:45:52.314869Z",
     "shell.execute_reply": "2024-01-12T09:45:52.314120Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem1_inversion returns a numpy array\n",
      "Good, your problem1_samples is a numpy array\n",
      "Good, your problem1_integral is a float\n",
      "Good, your problem1_interval is a tuple or list of length 2\n",
      "Good, your problem1_inversion_2 returns a numpy array\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion_2(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9950c4af",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:52.317974Z",
     "iopub.status.busy": "2024-01-12T09:45:52.317642Z",
     "iopub.status.idle": "2024-01-12T09:45:52.919058Z",
     "shell.execute_reply": "2024-01-12T09:45:52.918153Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "TEST",
    "lx_problem_number": "1",
    "lx_problem_points": "14",
    "lx_test_only": "True"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbQUlEQVR4nO3deZhcdZ3v8fcn+9ZJd5ImOzQg+6JAIygqKKKMqOgzjBdXZJzhUa9e9Xq9InccdRzv4OM8Xp2Z63ijLDosOqOgKItmQEAQ0A5CAMMSkpA93UnvCVn7e/84p5Oi6XRXuqq7+pf6vJ6nnlN1zqlzvr+q5FO//tU5pxQRmJlZesZUugAzMxsaB7iZWaIc4GZmiXKAm5klygFuZpYoB7iZWaIc4FYUSSHpFQdY9mFJD4x0TTY0kr4s6YZK12Glc4Af4iStlvSipG5JmyVdJ2lapesqlqRPSGqStFPS9RWqoSH/ABtXMO8iSQ9Iape0SdL3JNVUoj6rXg7w6vCOiJgGnA6cCfxN4cLCYBqFNgB/D1xbiZ0P8NrMIKtrPnACsBD4xkjVZQYO8KoSEeuBO4GT8x7lf5X0HPAcgKS/lrRCUquk2yTN77OJt0laKWmLpG9I6vffj6TjJS3Jt/OMpPcULLte0nck3Zn/VfCgpLmSviWpTdLTkk4rqPmWiPgZsLXYdko6T9I6SVflta6W9P6C5RdJ+qOkTklrJX25YFlvb/sjktYA9wD354vb85pfExE3RcRdEbE9ItqA7wHnFFHbh/PXsEvSqt66JB0t6R5JW/Oab5RUW/C81ZI+J2mZpG2SrpE0J38duyT9p6S6Pm24QtIGSRslfXaAms6W9Lv8r4nHJZ03WL02SkSEb4fwDVgNvDm/vwh4CvgqEMASYCYwGXgTsIWslz4R+Gfg/oLtBPCbfP3DgWeBv8qXfRh4IL8/FVgLXA6My7e3BTgpX359/vgMYBJZQK4CPgSMJevV/qafdvw9cH2RbT4P2AN8M2/LucA24LiC5aeQdWBOBTYD78qXNeRt/WHelskF88YNsM9vAT8apK6pQGdBHfMKXpdXABfk9daTfWh8q8/7+DAwB1gANAOPAqflz7kH+FKfNtyc7/MUoKXg38GXgRvy+wvIPhzflr8eF+SP6weq17fRcXMPvDr8TFI78ABwH/C/8/n/EBGtEfEi8H7g2oh4NCJ2Al8AXiOpoWA7X8/XX0MWWO/tZ19vB1ZHxHURsSciHgV+ClxSsM6tEbE0InYAtwI7IuKHEbEX+DFZKJXDFyNiZ0TcB9wOvAcgIu6NiCcioicilpEF3bl9nvvliNiWvzYDknQBcBnwt0XU1EP2F9DkiNgYEU/lNa2IiCV5vS1kHz59a/rniNgc2V9SvwUeiYg/5u/Xrbz8dftK3oYngOvo//36AHBHRNyRvx5LgCayQD9gvTY6OMCrw7siojYijoiIjxeE0tqCdeYDL/Q+iIhusp7YgoJ1Ctd/IX9OX0cAZ+V/jrfnHxzvB+YWrLO54P6L/Twux5esbRGxrb96JZ0l6TeSWiR1AB8FZvd5/lqKIOls4Cbgkoh4dqB183r+S76/jZJul3R8vp3DJP1I0npJncAN/dR0sK9bse/XX/R5v14HzBuoXhsdHODVrfBSlBvI/jMDIGkqMAtYX7DOooL7h+fP6WstcF/+gdF7mxYRHytj3cWoy9vQq7Dem4DbgEURMQP4LqA+z48D3N8nH6u/DfjLiLi7mKIi4lcRcQHZcMTTZGPnAP+Q7+fUiJhO1jPuW9PBKvb9+rc+79fUiLh6kHptFHCAW6+bgMslvUrSRLJhlkciYnXBOp+TVCdpEfApsuGOvn4JHCvpg5LG57czJZ0wlKIkjZM0iWx8fKykSQdx1MxXJE2Q9HqyoZ3/yOfXAK0RsUPSq4H3DbKdFrKhhKMK6joZuAv4ZET8osi2zJH0zvyDZSfQDewtqKmb7IvSBcDnimrhwL4oaYqkk8i+k+jv/boBeIekt0rqfX3Pk7RwkHptFHCAGwB5D/KLZOPVG4GjgUv7rPZzYCnwGNmY8jX9bKcLeEv+3A3AJuDrZF+0DcXfkA0PXEnWK32RPodBHsAmoC2v4UbgoxHxdL7s48DfSeoiG7f+94E2FBHbga8BD+bDDGcDnyX7ou+a/MiUbkmDjQ+PyZ+3AWglG+P+eL7sK2Rf+HaQvba3FNHGwdwHrADuBv4xIn7dd4WIWAtcDFxF9kG1luzDY8wg9doooAj/oIMdWvLD4G6IiIUVLqUi8i+eVwHjI2JPhcuxYeQeuJlZohzglqT8JJ3ufm53joLa+qurOx+LNysbD6GYmSXKPXAzs0SN6EWMZs+eHQ0NDSO5SzOz5C1dunRLRNT3nT+iAd7Q0EBTU9NI7tLMLHmSXuhvvodQzMwS5QA3M0uUA9zMLFEOcDOzRDnAzcwS5QA3M0uUA9zMLFEOcDOzRDnAzcwSNaJnYpai4crb991fffVFFazEzGx0cA/czCxRDnAzs0Q5wM3MEuUANzNLlAPczCxRDnAzs0Q5wM3MEuUANzNLlAPczCxRgwa4pGslNUt6smDeNyQ9LWmZpFsl1Q5rlWZm9jLF9MCvBy7sM28JcHJEnAo8C3yhzHWZmdkgBg3wiLgfaO0z79cRsSd/+DCwcBhqMzOzAZRjDPwvgTsPtFDSFZKaJDW1tLSUYXdmZgYlBrik/wXsAW480DoRsTgiGiOisb6+vpTdmZlZgSFfTlbSZcDbgfMjIspXkpmZFWNIAS7pQuDzwLkRsb28JZmZWTGKOYzwZuAh4DhJ6yR9BPgXoAZYIukxSd8d5jrNzKyPQXvgEfHefmZfMwy1mJnZQfCZmGZmiXKAm5klygFuZpYoB7iZWaIc4GZmiXKAm5klygFuZpYoB7iZWaIc4GZmiXKAm5klygFuZpYoB7iZWaIc4GZmiXKAm5klygFuZpYoB7iZWaIc4GZmiXKAm5klygFuZpYoB7iZWaIc4GZmiXKAm5klygFuZpaoQQNc0rWSmiU9WTBvpqQlkp7Lp3XDW6aZmfVVTA/8euDCPvOuBO6OiGOAu/PHZmY2ggYN8Ii4H2jtM/ti4Af5/R8A7ypvWWZmNpihjoHPiYiNAPn0sAOtKOkKSU2SmlpaWoa4OzMz62vYv8SMiMUR0RgRjfX19cO9OzOzqjHUAN8saR5APm0uX0lmZlaMoQb4bcBl+f3LgJ+XpxwzMytWMYcR3gw8BBwnaZ2kjwBXAxdIeg64IH9sZmYjaNxgK0TEew+w6Pwy12JmZgfBZ2KamSXKAW5mligHuJlZohzgZmaJcoCbmSXKAW5mligHuJlZohzgZmaJcoCbmSXKAW5mligHuJlZohzgZmaJcoCbmSXKAW5mligHuJlZohzgZmaJcoCbmSXKAW5mligHuJlZohzgZmaJcoCbmSXKAW5mligHuJlZohzgZmaJKinAJX1G0lOSnpR0s6RJ5SrMzMwGNuQAl7QA+G9AY0ScDIwFLi1XYWZmNrBSh1DGAZMljQOmABtKL8nMzIox5ACPiPXAPwJrgI1AR0T8uu96kq6Q1CSpqaWlZeiVmpnZS5QyhFIHXAwcCcwHpkr6QN/1ImJxRDRGRGN9ff3QKzUzs5coZQjlzcCqiGiJiN3ALcBry1OWmZkNppQAXwOcLWmKJAHnA8vLU5aZmQ2mlDHwR4CfAI8CT+TbWlymuszMbBDjSnlyRHwJ+FKZajEzs4PgMzHNzBLlADczS5QD3MwsUQ5wM7NEOcDNzBLlADczS5QD3MwsUQ5wM7NEOcDNzBLlADczS5QD3MwsUQ5wM7NEOcDNzBLlADczS5QD3MwsUQ5wM7NEOcDNzBLlADczS5QD3MwsUQ5wM7NEOcDNzBLlADczS5QD3MwsUSUFuKRaST+R9LSk5ZJeU67CzMxsYONKfP63gbsi4hJJE4ApZajJzMyKMOQAlzQdeAPwYYCI2AXsKk9ZZmY2mFKGUI4CWoDrJP1R0vclTe27kqQrJDVJamppaSlhd2ZmVqiUAB8HnA78a0ScBmwDruy7UkQsjojGiGisr68vYXdmZlaolABfB6yLiEfyxz8hC3QzMxsBQw7wiNgErJV0XD7rfOBPZanKzMwGVepRKJ8EbsyPQFkJXF56SWZmVoySAjwiHgMay1OKmZkdDJ+JaWaWKAe4mVmiHOBmZolygJuZJarUo1AqouHK2/fdX331RRWsxMysctwDNzNLlAPczCxRDnAzs0Q5wM3MEuUANzNLlAPczCxRDnAzs0Q5wM3MEuUANzNLlAPczCxRDnAzs0Q5wM3MEuUANzNLlAPczCxRDnAzs0Q5wM3MEuUANzNLlAPczCxRJQe4pLGS/ijpl+UoyMzMilOOHvingOVl2I6ZmR2Ekn7UWNJC4CLga8B/L0tFB8k/cGxm1arUHvi3gP8J9BxoBUlXSGqS1NTS0lLi7szMrNeQA1zS24HmiFg60HoRsTgiGiOisb6+fqi7MzOzPkrpgZ8DvFPSauBHwJsk3VCWqszMbFBDDvCI+EJELIyIBuBS4J6I+EDZKjMzswH5OHAzs0SVdBRKr4i4F7i3HNsyM7PiuAduZpYoB7iZWaIc4GZmiXKAm5klygFuZpaoshyFMlr4uihmVk3cAzczG27dzcOyWQe4mdlwaV8Dv/wMfPNEWPXbsm/+kBpCMTMbFVpXwQP/Bx67KXt8+gdh5pFl340D3MysXJqXZ8H9xE9gzFg44zJ43WdgxsJh2Z0D3MysVGsegQe/Dc/cDuOnwNkfg9d8AqbPG9bdOsDNzIaipweevRMe/CdY+zBMroNzPw9nfRSmzByREhzgZmYHY9d2ePwmeOg70Po8zFgEF349G+eeMHVESzlkA9zHhJtZWbWvhT98D5b+AHa0w/zT4ZJr4YSLYWxlovSQDXAzs5JFwOrfwu8Xw9N3ZPNOeDuc9TE4/GyQKlqeA9zMrK8dHfD4j6HpGmh5GibPhNd+As78a6hdVOnq9nGAm5lB1tve8Cg0XQdP/hR2b4f5p8G7/hVOejeMn1zpCl/GAW5m1e3FNlj2H/DoD2Dzk9lhgKdcAmdcDgtOr3R1A3KAm1n16dkLK++Fx26E5b+EvTth3ivhom9m4T1pRqUrLEpVBLiPSDEzAFqehcdvhmU/hs71MKkWTv8QnPYBmP+qSld30KoiwAs5zM2qTHdzNqa97N+zMW6NhVecD2/5Khx3EYyfVOkKh6zqAtzMqsCODnj69uyaJCvvhdgLc0+Ft3wNTvkLqJlT6QrLwgFuZoeGnV3w7K/gqVvhuV/D3l1Qezi87tNwynvgsOMrXWHZDTnAJS0CfgjMBXqAxRHx7XIVZmY2qB2dWWgv/zk8twT27IBpc6HxI3Dyn8PCxoqfbDOcSumB7wE+GxGPSqoBlkpaEhF/KlNtw65wPBw8Jm6WhG1b4Jk7YfkvYOVvsp72tLnZl5EnvRsWnQ1jquO3aoYc4BGxEdiY3++StBxYACQT4GaWiK3PwzN3ZMG95iGIHphxeHZm5InvhIWvrprQLlSWMXBJDcBpwCPl2F6l+AgVs1Fi725Y+0g2PPLsXbDl2Wz+YSfBGz4Hx1+UfSl5CA+PFKPkAJc0Dfgp8OmI6Oxn+RXAFQCHH354qbsbMQ5zsxHWtRlW/CesWALP35MdSTJmPBzxWjjzr+DYC6HuiEpXOaqUFOCSxpOF940RcUt/60TEYmAxQGNjY5SyPzM7hOzZlfWyn78bVtwNm5Zl86fNhePfAce+FY5+I0ysqWydo1gpR6EIuAZYHhHfLF9JZnZIish+M3LlvdmXj6sfhN3bYMw4WHQWvOmLcMxbYO4pVT80UqxSeuDnAB8EnpD0WD7vqoi4o+SqzCx9EdC2Clb9Flbdn922NWfLZh4Nr3pf1sNueD1Mml7ZWhNVylEoDwBV8THZ93DDXh4bNysQAa0r4YUH4YXfZcHduS5bNvUwOOpcOPLcbFqbzvdho5nPxDSzoenZmw2JrHkoC+w1D0HXxmzZlNnQcA40fBqOfAPMPtbDIsPAAV4CH6liVWVnN6xfCmt/n/0K+9o/wM6ObFnN/OxokSPOgYbXObBHiAO8TBzmdkjp6cmGQ9b9Ib/9HjY/lZ1AA1B/Apycn/V4xGug9ggHdgU4wIeBw9yS07UJ1j+aXW51/dLstiPvXU+oyX6Z5vX/IztaZOEZMLmusvUa4AAfdg5zG3W6m2HDY7DxsWy64Y/QtSFbprFw2InZNUUWnAELz8yGQ8aMrWDBdiAO8BHko1lsREVA+wuwcRlseiI7UWbj4/u/aEQw6xXZmPWC07Mf8J17KkyYUtGyrXgO8FHAvXQr2a5t0Px09qO8m5+ETfl0Z351C42B2cdlh/HNOzX7/ce5p/r468Q5wEcZh7kNaO/u7Mp8zX/KDuFr/lN2a10F5FeqmDAN5pyU/fLM3JNh7ithzokwfnJFS7fyc4CPYg7zKrZnZ3YUSMsz+W15Nt3yHPTsztbRmOyMxrmnwKmXZqE956TsiJAqvLRqNXKAm1XS9tYslLc+l10ydUs+bV2V/Y4jAMquwld/QnaBp/oTsp8Hm32se9VVzgGeiAN9AVoM994rbNe2rDe9dUU2/NG6Mg/tFfBi6/71xk7IetS9R4HMPg7qj4VZx/iLReuXA7wKFBP+DvkSvdiW9ZrbVu2fbl2ZhXX3ppeuWzMvO/rjhHfA7GOygJ59TDb0Mdb/Ja14/tdiwMAh73AnG5PuWAdtq7ND89pWQ1vvdNX+k156TZuT9aZf8WaY2ZAF9syjYeZRMHHayNdvhyQHuA2qKnrwu7ZnAd2xBtrXQsdaaF+T39bmx04X/B7J2AnZFfVqj8h++byuIbvNPCqbTphamXZYVXGAW1kUc8RMxY6q2bsnG8boWJ9d3rRjPXSuzwN7bTbdvvWlz9FYmLEgC+ij37g/rOuOyKY183ykh1WcA9zKrpgee9l69bt3ZKeBd27Mesmd67P7neuzxx3rs/DuvQhTrwk1MGNhFtLzT8/vL4LaRVlY18zz6eM26jnAbVSawG7OufJ6DlN7fmtjjtqYQ9u+x3PVRp26X/bc7pjEtPo8hI9+I0yfn98W8tbrnmdjzKJzx1RWX5X4sI9VPQe4jRjRQx3dzFYH9WpnNh3U5/cPUzv1tO8L7Fpte9nz98QYmqmlOWpZF4fR1HMcm2ImzdSyMWaxKerYHDPpYgqs66+C3cD+X4LxtWksdQ5wK8lEdjGTLmapg9nqZBad+++rg3qy+7PVwUw6Gaeel21jR4ynJWppppaVMZ+He06kOX/cErU0Rx2bo45Wauhh+MedSznmvq9Svg/wmbg2GAe4FQgms5NZ6qKOLmapkzq6mKlOZqmLmeTTPKhnqpPperHfLe2I8WxhBltiOutjFo/3HJU/nkFLZNMtzKA5aulmMofqz6se7IfBgdY/2O0UE/j+gEifImLwtcqksbExmpqahvTccvaKqkMwhZ3U0UWtupmpLuropjaf1qkrn5dNa9XNTLqYrF39bm13jKWVGlpjOlujhq3MoDVq2BIz2Mr0ffe35PMP5VCuJoXBPhJ/mVj/JC2NiMa+890DT8BEdlFLN7XqppZt2VTd1NJNnbqZkU/3z+uilm4mas8Bt9keU2mLabRTw8aYyVM9DbQxjdaYTis1tEUNrVHDVqbTFjV0MgUHcvUZro7TaOiQlevD6UDbGYkPKffAR8g49jCd7czQNmawbd90urZRSzczCqa993sDe6J2H3C7O2Mc7UyjPabtm/YGc1tMo23fvBpaqdm33l58iJzZSCol0N0DL1kwiV1MZzvTtW1fGE8vCOP9obz9JQE9g21M044Bt74tJtLBVDpiKu1Rw0rm0dEzlXZqaI+pdDB1X/h25r3nNqbxIhNxz9isOpUU4JIuBL4NjAW+HxFXl6WqYTKB3S8J4P3T7UzvDd48dF86P3s80JAE7A/hzjxw10U9HdFAR2TB3BvQL51Oo5Mp7GL8CL0KZnaoGHKASxoL/F/gArKjbv8g6baI+FO5inupYCK79wVt3+AtDOSaPo9715s0wFAEwK4YSydT6YrJ+4J4PbPo7Jm673EnU+jIp50FYdzFFHb7DxozG0GlJM6rgRURsRJA0o+Ai4HyB/hdV/HMxP83aA+4N4A7YwpdedBuYBZdPVPyAN4/v5MpdMWUlwTzDibg4QgzS0UpAb4AWFvweB1wVt+VJF0BXJE/7Jb0zBD3NxvYMvhqbUPc/KhUZJsPKW5zdai6NuvrJbX5iP5mlhLg/XVVX3ZIS0QsBhaXsJ9sZ1JTf9/CHsrc5urgNleH4WhzKeclrwMWFTxeCGworRwzMytWKQH+B+AYSUdKmgBcCtxWnrLMzGwwQx5CiYg9kj4B/IrsMMJrI+KpslX2ciUPwyTIba4ObnN1KHubR/RMTDMzKx//JpSZWaIc4GZmiRp1AS7pQknPSFoh6cp+lkvSP+XLl0k6vRJ1llMRbX5/3tZlkn4n6ZWVqLOcBmtzwXpnStor6ZKRrK/cimmvpPMkPSbpKUn3jXSN5VbEv+sZkn4h6fG8zZdXos5yknStpGZJTx5geXnzKyJGzY3sy9DngaOACcDjwIl91nkbcCfZcehnA49Uuu4RaPNrgbr8/p9VQ5sL1rsHuAO4pNJ1D/N7XEt2FvPh+ePDKl33CLT5KuDr+f16oBWYUOnaS2z3G4DTgScPsLys+TXaeuD7Ts+PiF1A7+n5hS4GfhiZh4FaSfNGutAyGrTNEfG7iOg9xfRhsmPuU1bM+wzwSeCnQPNIFjcMimnv+4BbImINQERUQ5sDqJEkYBpZgA98vYxRLiLuJ2vHgZQ1v0ZbgPd3ev6CIayTkoNtz0fIPsFTNmibJS0A3g18dwTrGi7FvMfHAnWS7pW0VNKHRqy64VFMm/8FOIHsBMAngE9FxMt/NPXQUtb8Gm2Xzyvm9PyiTuFPSNHtkfRGsgB/3bBWNPyKafO3gM9HxN6sg5a0Yto7DjgDOB+YDDwk6eGIeHa4ixsmxbT5rcBjwJuAo4Elkn4bEZ3DXFsllTW/RluAF3N6/qF2Cn9R7ZF0KvB94M8iYusI1TZcimlzI/CjPLxnA2+TtCcifjYiFZZXsf+ut0TENmCbpPuBVwKpBngxbb4cuDqyweEVklYBxwO/H5kSK6Ks+TXahlCKOT3/NuBD+be5ZwMdEbFxpAsto0HbLOlw4Bbggwn3yAoN2uaIODIiGiKiAfgJ8PFEwxuK+3f9c+D1ksZJmkJ2Zc/lI1xnORXT5jVkf3EgaQ5wHLByRKsceWXNr1HVA48DnJ4v6aP58u+SHZHwNmAFsJ3sUzxZRbb5b4FZwHfyHumeSPhKbkW2+ZBRTHsjYrmku4BlQA/ZL1z1eyhaCop8j78KXC/pCbKhhc9HRNKXmJV0M3AeMFvSOuBLkP3c1nDkl0+lNzNL1GgbQjEzsyI5wM3MEuUANzNLlAPczCxRDnAzs0Q5wM3MEuUANzNL1P8H9LsnPE5UNucAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning tests for problem 1\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part1\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "You are producing the correct number of samples when asking for 10\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your sampler produces samples that are too far away from the true distribution\n",
      "You got 3.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part2\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "You produced 100000 samples, good!\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your samples are too far away from the true distribution\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: -1\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part3\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your answer to problem1_integral is not within 0.01 from the correct approximation\n",
      "You got 2.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part4\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your confidence interval is correct\n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part5\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Managed to produce 1000 samples within 10 seconds\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your sampler produces samples that are too far away from the true distribution\n",
      "You got 3.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "\n",
      "All tests complete, you got = 4.50 points\n",
      "The number of points you have scored for this problem is 4.5 out of 14\n",
      "The number of points you have accumulated thus far is   4.5 out of 14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "872c599b",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6fdf96",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Let us build a proportional model ($\\mathbb{P}(Y=1 \\mid X) = G(\\beta_0+\\beta \\cdot X)$ where $G$ is the logistic function) for the spam vs not spam data. Here we assume that the features are presence vs not presence of a word, let $X_1,X_2,X_3$ denote the presence (1) or absence (0) of the words $(\"free\", \"prize\", \"win\")$.\n",
    "\n",
    "1. [2p] Load the file `data/spam.csv` and create two numpy arrays, `problem2_X` which has shape (n_emails,3) where each feature in `problem2_X` corresponds to $X_1,X_2,X_3$ from above, `problem2_Y` which has shape **(n_emails,)** and consists of a $1$ if the email is spam and $0$ if it is not. Split this data into a train-calibration-test sets where we have the split $40\\%$, $20\\%$, $40\\%$, put this data in the designated variables in the code cell.\n",
    "\n",
    "2. [4p] Follow the calculation from the lecture notes where we derive the logistic regression and implement the final loss function inside the class `ProportionalSpam`. You can use the `Test` cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "3. [4p] Train the model `problem2_ps` on the training data. The goal is to calibrate the probabilities output from the model. Start by creating a new variable `problem2_X_pred` (shape `(n_samples,1)`) which consists of the predictions of `problem2_ps` on the calibration dataset. Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`, store this trained model in `problem2_calibrator`.\n",
    "\n",
    "4. [3p] Use the trained model `problem2_ps` and the calibrator `problem2_calibrator` to make final predictions on the testing data, store the prediction in `problem2_final_predictions`. Compute the $0-1$ test-loss and store it in `problem2_01_loss` and provide a $99\\%$ confidence interval of it, store this in the variable `problem2_interval`, this should again be a tuple as in **problem1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b9eb2a",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:52.922714Z",
     "iopub.status.busy": "2024-01-12T09:45:52.922270Z",
     "iopub.status.idle": "2024-01-12T09:45:53.036464Z",
     "shell.execute_reply": "2024-01-12T09:45:53.035652Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2228, 3) (1115, 3) (2229, 3) (2228,) (1115,) (2229,)\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "def load_sms():\n",
    "    import csv\n",
    "    lines = []\n",
    "    hamspam = {'ham': 0, 'spam': 1}\n",
    "    with open('data/spam.csv', mode='r',encoding='latin-1') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)\n",
    "        lines = [(line[1],hamspam[line[0]]) for line in reader]\n",
    "        \n",
    "    return lines\n",
    "spam_no_spam = load_sms()\n",
    "#print(spam_no_spam)\n",
    "x1 = [ ]\n",
    "x2 = [ ]\n",
    "x3 = [ ]\n",
    "def getx(dataset,keyword):\n",
    "    x = []\n",
    "\n",
    "    for sms, is_spam in dataset:\n",
    "        # Splitting the SMS into words\n",
    "        words = sms.lower().split()\n",
    "        # Check if 'free' or 'prize' are present as complete words\n",
    "        has_keywords = keyword in words\n",
    "\n",
    "\n",
    "        if has_keywords:\n",
    "            x.append('1')\n",
    "        else:\n",
    "            x.append('0')\n",
    "    return x\n",
    "x1 = getx(spam_no_spam,\"free\")\n",
    "x2 = getx(spam_no_spam,\"prize\")\n",
    "x3 = getx(spam_no_spam,\"win\")\n",
    "#problem2_X = np.array([x1,x2,x3])\n",
    "problem2_X = np.array([x1,x2,x3],dtype='int') # Teacher edit: you need to convert everything from string to numbers\n",
    "problem2_X = problem2_X.transpose()\n",
    "def getY(dataset):\n",
    "    y = [ ]\n",
    "    for sms, is_spam in dataset:\n",
    "        if is_spam:\n",
    "            y.append('1')\n",
    "        else:\n",
    "            y.append('0')\n",
    "    return y\n",
    "Y = getY(spam_no_spam)\n",
    "#Y = np.array(Y) \n",
    "Y = np.array(Y,dtype='int') # Teacher edit: you need to convert everything from string to numbers\n",
    "problem2_Y = Y\n",
    "#print(problem2_X.shape)\n",
    "#print(problem2_Y.shape)\n",
    "def train_test_validation(X,Y,test_size=0.2,validation_size=0.2,random_state=None,shuffle=True):\n",
    "    \"\"\"\n",
    "    Performs a train test validation split of the data [train_data,test_data,validation_data]\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : The input X, shape (n_samples,n_features)\n",
    "    Y : The input labells, shape (n_samples)\n",
    "    test_size : the proportion of data that should be test data\n",
    "    validation_size : the proportion of data that should be validation data\n",
    "    random_state : the random state variable passed through to sklearns train_test_split\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    X_train, X_test, X_valid, Y_train, Y_test, Y_valid\n",
    "\n",
    "    Examples:\n",
    "    ----------\n",
    "    >>> X_train, X_test, X_valid, Y_train, Y_test, Y_valid = train_test_validation(X,Y,test_size=0.25,validation_size=0.25)\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train,X_tt,Y_train,Y_tt = train_test_split(X,Y,\n",
    "                                                 test_size=test_size+validation_size,\n",
    "                                                 random_state=random_state,\n",
    "                                                 shuffle=shuffle)\n",
    "    X_test,X_valid,Y_test,Y_valid = train_test_split(X_tt,Y_tt,\n",
    "                                                     test_size=(validation_size)/(test_size + validation_size),\n",
    "                                                     random_state=random_state,\n",
    "                                                     shuffle=shuffle)\n",
    "\n",
    "    return X_train, X_test, X_valid, Y_train, Y_test, Y_valid\n",
    "\n",
    "#problem2_X_train = XXX\n",
    "#problem2_X_calib = XXX\n",
    "#problem2_X_test = XXX\n",
    "\n",
    "#problem2_Y_train = XXX\n",
    "#problem2_Y_calib = XXX\n",
    "#problem2_Y_test = XXX\n",
    "problem2_X_train,problem2_X_test,problem2_X_calib,problem2_Y_train,problem2_Y_test,problem2_Y_calib = train_test_validation(problem2_X,problem2_Y,test_size = 0.4,validation_size = 0.2)\n",
    "print(problem2_X_train.shape,problem2_X_calib.shape,problem2_X_test.shape,problem2_Y_train.shape,problem2_Y_calib.shape,problem2_Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f371e814",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.040045Z",
     "iopub.status.busy": "2024-01-12T09:45:53.039769Z",
     "iopub.status.idle": "2024-01-12T09:45:53.048935Z",
     "shell.execute_reply": "2024-01-12T09:45:53.047850Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        #cost = np.transpose(-y)@np.log(h) - np.transpose(1-y)@np.log(1-h) + (l/2)*np.transpose(t[1:])@t[1:]\n",
    "        #cost = (1/m)*cost\n",
    "        #return cost\n",
    "        y_hat = self.predict(X) # Teacher: this is not correct and predict wont work since the model is not trained\n",
    "        # Teacher: since it is not trained y_hat will be None and everything fails\n",
    "        return 0 # Teacher edit: to make the code run\n",
    "        #lossvalue = -np.mean(Y*np.log(y_hat) + (1- Y )*np.log(1-y_hat))\n",
    "        #return lossvalue\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        #Use the f above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "            return np.round(10*G(np.dot(X,self.coeffs[1:])+self.coeffs[0]))/10 # This rounding is to help you with the calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "287799cf",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.052522Z",
     "iopub.status.busy": "2024-01-12T09:45:53.052096Z",
     "iopub.status.idle": "2024-01-12T09:45:53.089133Z",
     "shell.execute_reply": "2024-01-12T09:45:53.087764Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "problem2_ps = ProportionalSpam()\n",
    "problem2_ps.fit(problem2_X_train,problem2_Y_train)\n",
    "problem2_X_pred = problem2_ps.predict(problem2_X_calib)\n",
    "\n",
    "\n",
    "#train DecisonTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "problem2_calibrator = DecisionTreeRegressor()\n",
    "problem2_calibrator.fit(problem2_X_train,problem2_Y_train)\n",
    "DecisionTreeRegressorproblem2_X_pred = problem2_calibrator.predict(problem2_X_calib)\n",
    "#print(DecisionTreeRegressorproblem2_X_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "749ca3fa",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.092540Z",
     "iopub.status.busy": "2024-01-12T09:45:53.092224Z",
     "iopub.status.idle": "2024-01-12T09:45:53.099999Z",
     "shell.execute_reply": "2024-01-12T09:45:53.099252Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "import numpy as np\n",
    "# These are the predicted probabilities\n",
    "problem2_final_predictions = problem2_calibrator.predict(problem2_X_test)\n",
    "\n",
    "\n",
    "# In order to compute this loss we first need to convert the predicted probabilities to a decision\n",
    "# recall the Bayes classifier?\n",
    "problem2_01_loss = (problem2_final_predictions - problem2_Y_test).sum()\n",
    "\n",
    "# Recall the interval is given as a tuple (a,b) or a list [a,b]\n",
    "def hoeffding_interval(sample_mean, n, a, b, confidence_level=0.95):\n",
    "    epsilon = np.sqrt(np.log(2 / (1 - confidence_level)) / (2 * n))\n",
    "    return max(a, sample_mean - epsilon * (b - a)), min(b, sample_mean + epsilon * (b - a))\n",
    "sa_avg = np.mean(problem2_final_predictions)\n",
    "n = len(problem2_final_predictions)\n",
    "a = 0.0\n",
    "b = 1.0 \n",
    "problem2_interval = hoeffding_interval(sa_avg,n,a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c89427",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96368dc2",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.103226Z",
     "iopub.status.busy": "2024-01-12T09:45:53.102960Z",
     "iopub.status.idle": "2024-01-12T09:45:53.108821Z",
     "shell.execute_reply": "2024-01-12T09:45:53.108102Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was not correct on a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738c3ad4",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.111942Z",
     "iopub.status.busy": "2024-01-12T09:45:53.111665Z",
     "iopub.status.idle": "2024-01-12T09:45:53.141548Z",
     "shell.execute_reply": "2024-01-12T09:45:53.140677Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "TEST",
    "lx_problem_number": "2",
    "lx_problem_points": "13",
    "lx_test_only": "True"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning tests for problem 2\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part1\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_X has the correct shape\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_Y has the correct shape\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_X_train has the correct number of features\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_X_calib has the correct number of features\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_X_test has the correct number of features\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_Y_train has the correct shape\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_Y_calib has the correct shape\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "problem2_Y_test has the correct shape\n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "Your problem2_X and problem2_Y where arrays of strings, not particularly useful. I changed it to int to make the rest of the code work!\n",
      "---------------------------------\n",
      "Beginning test for part2\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your loss does not produce a number as output\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your supplied loss differs more than 1e-3 from the reference even when correcting for the 2y-1 mistake\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your supplied loss differs more than 1e-3 from the reference\n",
      "You got 2.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "Your loss was not working so I commented it out to at least make the code run!\n",
      "---------------------------------\n",
      "Beginning test for part3\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Your optimization succeeded\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your problem2_X_pred does not have the correct shape\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your problem2_X_pred is correctly defined\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your calibrator has the correct type\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Your calibrator is trained, good!\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "X has 1 features, but DecisionTreeRegressor is expecting 3 features as input.\n",
      "Your calibrator is not trained on the correct thing\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part4\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "X has 1 features, but DecisionTreeRegressor is expecting 3 features as input.\n",
      "Your final predictions differ from the output of your calibrator and model together\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your 01 loss differs from more than 1e-3 from the 01 loss computed using your predictions\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Your interval differs more than 1e-3 combined on both the lower and upper\n",
      "You got 1.0 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "\n",
      "All tests complete, you got = 4.00 points\n",
      "The number of points you have scored for this problem is 4.0 out of 13\n",
      "The number of points you have accumulated thus far is   8.5 out of 27\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d70d34a3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4631a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "source": [
    "\n",
    "Consider the following four Markov chains, answer each question for all chains:\n",
    "\n",
    "<img width=\"400px\" src=\"pictures/MarkovA.png\">Markov chain A</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovB.png\">Markov chain B</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovC.png\">Markov chain C</img>\n",
    "<img width=\"400px\" src=\"pictures/MarkovD.png\">Markov chain D</img>\n",
    "\n",
    "1. [2p] What is the transition matrix?\n",
    "2. [2p] Is the Markov chain irreducible?\n",
    "3. [3p] Is the Markov chain aperiodic? What is the period for each state?\n",
    "4. [3p] Does the Markov chain have a stationary distribution, and if so, what is it?\n",
    "5. [3p] Is the Markov chain reversible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d121095",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.145333Z",
     "iopub.status.busy": "2024-01-12T09:45:53.144498Z",
     "iopub.status.idle": "2024-01-12T09:45:53.152992Z",
     "shell.execute_reply": "2024-01-12T09:45:53.152033Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 1\n",
    "\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "import numpy as np\n",
    "\n",
    "problem3_A = np.array([[0.8, 0.2, 0.0, 0.0],\n",
    "              [0.6, 0.2, 0.2, 0.0],\n",
    "              [0.0, 0.4, 0.0, 0.6],\n",
    "              [0.0, 0.0, 0.8, 0.2]])\n",
    "problem3_B   = np.array([[0.0,0.2,0.0,0.8],\n",
    "                          [0.0,0.0,1.0,0.0],\n",
    "                          [0.0,1.0,0.0,0.0],\n",
    "                          [0.5,0.0,0.5,0.0]])\n",
    "problem3_C   = np.array([[0.2,0.3,0.0,0.0,0.5],\n",
    "                          [0.2,0.2,0.6,0.0,0.0],\n",
    "                          [0.0,0.4,0.0,0.6,0.0],\n",
    "                          [0.0,0.0,0.0,0.6,0.4],\n",
    "                          [0.0,0.0,0.0,0.4,0.6]])\n",
    "problem3_D   = np.array([[0.8,0.2,0.0,0.0],\n",
    "                          [0.6,0.2,0.2,0.0],\n",
    "                          [0.0,0.4,0.0,0.6],\n",
    "                          [0.1,0.0,0.7,0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1aa1142",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.156326Z",
     "iopub.status.busy": "2024-01-12T09:45:53.155999Z",
     "iopub.status.idle": "2024-01-12T09:45:53.161855Z",
     "shell.execute_reply": "2024-01-12T09:45:53.160683Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "'''Irreducibility: a Markov chain is irreducible if its state space has only one connected class, \n",
    "i.e., the full membership of the state space,\n",
    "and the irreducibility of a Markov chain implies \n",
    "that the random variable can be transferred between any states during its evolution .'''\n",
    "problem3_A_irreducible = True\n",
    "problem3_B_irreducible = False\n",
    "problem3_C_irreducible = True\n",
    "problem3_D_irreducible = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a47c34e",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.165343Z",
     "iopub.status.busy": "2024-01-12T09:45:53.165019Z",
     "iopub.status.idle": "2024-01-12T09:45:53.170641Z",
     "shell.execute_reply": "2024-01-12T09:45:53.169806Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "# Answer each one with a True or False\n",
    "'''Non-periodic: an MC,there does not exist a state from which the length of time elapsed \n",
    "before returning to this state is periodic, \n",
    "Theorem: Irreducible and non-periodic finite state Markov chains with a unique smooth distribution.'''\n",
    "problem3_A_is_aperiodic = True\n",
    "problem3_B_is_aperiodic = False\n",
    "problem3_C_is_aperiodic = False\n",
    "problem3_D_is_aperiodic = True\n",
    "\n",
    "# Answer the following with the period of the states as a numpy array\n",
    "# of shape (n_states,)\n",
    "\n",
    "problem3_A_periods = np.array([1,1,1,1])\n",
    "problem3_B_periods = np.array([1,1,1,1])\n",
    "problem3_C_periods = np.array([2,2,1,2,2])\n",
    "problem3_D_periods = np.array([2,2,2,2])\n",
    "#print(problem3_A_periods.shape)\n",
    "#print(problem3_B_periods.shape)\n",
    "#print(problem3_C_periods.shape)\n",
    "#print(problem3_D_periods.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b7a60e",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.173736Z",
     "iopub.status.busy": "2024-01-12T09:45:53.173386Z",
     "iopub.status.idle": "2024-01-12T09:45:53.181453Z",
     "shell.execute_reply": "2024-01-12T09:45:53.180576Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 4\n",
    "import numpy as np\n",
    "def getstationary(P):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)  \n",
    "    stationary_distribution = np.real(eigenvectors[:, 0] / eigenvectors[:, 0].sum()) \n",
    "    answer_stationary = stationary_distribution\n",
    "    return answer_stationary\n",
    "def isver(P):\n",
    "    isnotinverse = 0\n",
    "    inverse =  1\n",
    "    import numpy as np\n",
    "    if np.linalg.det(P) == 0:\n",
    "        return isnotinverse\n",
    "    else:\n",
    "        return inverse\n",
    "#------------------------STATIONARY DISTRIBUTION-----------------\n",
    "# Answer each one with a True or False\n",
    "#A = isver(problem3_D)\n",
    "problem3_A_has_stationary = True\n",
    "problem3_B_has_stationary = True\n",
    "problem3_C_has_stationary = True\n",
    "problem3_D_has_stationary = True\n",
    "\n",
    "# Answer the following with the stationary distribution as a numpy array of shape (n_states,)\n",
    "# if the Markov chain has a stationary distribution otherwise answer with False\n",
    "#A = \n",
    "problem3_A_stationary_dist = getstationary(problem3_A)\n",
    "problem3_B_stationary_dist = getstationary(problem3_B)\n",
    "problem3_C_stationary_dist = getstationary(problem3_C)\n",
    "problem3_D_stationary_dist = getstationary(problem3_D)\n",
    "\n",
    "#print(problem3_A_stationary_dist.shape)\n",
    "#print(problem3_B_stationary_dist.shape)\n",
    "#print(problem3_C_stationary_dist.shape)\n",
    "#print(problem3_D_stationary_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6449934f",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.184670Z",
     "iopub.status.busy": "2024-01-12T09:45:53.184302Z",
     "iopub.status.idle": "2024-01-12T09:45:53.189428Z",
     "shell.execute_reply": "2024-01-12T09:45:53.188644Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "13"
   },
   "outputs": [],
   "source": [
    "# PART 5\n",
    "#------------------------REVERSIBLE-----------------\n",
    "# Answer each one with a True or False\n",
    "'''The reversibility of a Markov chain is a stricter form of irreducibility,\n",
    "i.e., it not only transfers between arbitrary states, but also transfers to each state with equal probability, \n",
    "so that a reversible Markov chain is a sufficient non-necessary condition for a smooth Markov chain.'''\n",
    "problem3_A_is_reversible = False\n",
    "problem3_B_is_reversible = False\n",
    "problem3_C_is_reversible = False\n",
    "problem3_D_is_reversible = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c314c3d4",
   "metadata": {
    "deletable": false,
    "execution": {
     "iopub.execute_input": "2024-01-12T09:45:53.192949Z",
     "iopub.status.busy": "2024-01-12T09:45:53.192601Z",
     "iopub.status.idle": "2024-01-12T09:45:53.235126Z",
     "shell.execute_reply": "2024-01-12T09:45:53.234333Z"
    },
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "TEST",
    "lx_problem_number": "3",
    "lx_problem_points": "13",
    "lx_test_only": "True"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning tests for problem 3\n",
      "\n",
      "---------------------------------\n",
      "Beginning test for part1\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "You get a deduction for each mistake in the transition matrix_A: deduced_points 0.00\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "You get a deduction for each mistake in the transition matrix_B: deduced_points 0.00\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "You get a deduction for each mistake in the transition matrix_C: deduced_points 0.00\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "You get a deduction for each mistake in the transition matrix_D: deduced_points 0.00\n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part2\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Correct answer for Markov chain_A\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Correct answer for Markov chain_B\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Wrong answer for Markov chain_C\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Correct answer for Markov chain_D\n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part3\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "Correct answer if Markov chain_A is aperiodic\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Correct answer if Markov chain_B is aperiodic\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "Wrong answer if Markov chain_C is aperiodic\n",
      "You got 0.2 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "Correct answer if Markov chain_D is aperiodic\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_A, the number of points deduced is based on how many periods you got wrong: deduced_points 0.00\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_B, the number of points deduced is based on how many periods you got wrong: deduced_points 0.50\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_C, the number of points deduced is based on how many periods you got wrong: deduced_points 0.40\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_D, the number of points deduced is based on how many periods you got wrong: deduced_points 0.50\n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part4\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_A you got the correct answer if it is stationary\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "For Markov chain_B you got the wrong answer if it is stationary\n",
      "You got 0.2 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "For Markov chain_C you got the wrong answer if it is stationary\n",
      "You got 0.2 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_D you got the correct answer if it is stationary\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_A stationary_distribution, the number of points deduced is based on how many elements you got wrong: deduced_points 0.50\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "For Markov chain_B you got the wrong answer to the stationary distribution\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "For Markov chain_C you got the wrong answer to the stationary distribution\n",
      "You got 0.5 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "For Markov chain_D stationary_distribution, the number of points deduced is based on how many elements you got wrong: deduced_points 0.50\n",
      "-----Ending test---------\n",
      "\n",
      "Manual points: 0\n",
      "No comment!\n",
      "---------------------------------\n",
      "Beginning test for part5\n",
      "---------------------------------\n",
      "\n",
      "-----Beginning test------\n",
      "\n",
      "You got the wrong answer for Markov chain_A\n",
      "You got 0.8 points deduction \n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "You got the correct answer for Markov chain_B\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "You got the correct answer for Markov chain_C\n",
      "-----Ending test---------\n",
      "\n",
      "-----Beginning test------\n",
      "You got the correct answer for Markov chain_D\n",
      "-----Ending test---------\n",
      "\n",
      "\n",
      "All tests complete, you got = 7.60 points\n",
      "The number of points you have scored for this problem is 7.6 out of 13\n",
      " \n",
      " \n",
      " \n",
      "The number of points you have scored in total for this entire set of Problems is 16.1 out of 40\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "lx_assignment_number": "vB",
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}