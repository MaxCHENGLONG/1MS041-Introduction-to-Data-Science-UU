{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 2 for Course 1MS041\n",
    "Make         sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline         and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Random variable generation and transformation\n",
    "\n",
    "The purpose of this problem is to show that you can implement your own sampler, this will be built in the following three steps:\n",
    "\n",
    "1. [2p] Implement a Linear Congruential Generator where you tested out a good combination (a large $M$ with $a,b$ satisfying the Hull-Dobell (Thm 6.8)) of parameters. Follow the instructions in the code block.\n",
    "2. [2p] Using a generator construct random numbers from the uniform $[0,1]$ distribution.\n",
    "3. [4p] Using a uniform $[0,1]$ random generator, generate samples from \n",
    "\n",
    "$$p_0(x) = \\frac{\\pi}{2}|\\sin(2\\pi x)|, \\quad x \\in [0,1] \\enspace .$$\n",
    "\n",
    "Using the **Accept-Reject** sampler (**Algorithm 1** in TFDS notes) with sampling density given by the uniform $[0,1]$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem1_LCG(size=None, seed = 0):\n",
    "    \"\"\"\n",
    "    A linear congruential generator that generates pseudo random numbers according to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    seed : the starting point of the LCG, i.e. u0 in the notes.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    out : a list of the pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    a = 1664525\n",
    "    b =  1013904223\n",
    "    M  = 2 ** 32\n",
    "    new_seed = seed \n",
    "    out = [ ]\n",
    "    for _  in range(size if size is not None else 1):\n",
    "        new_seed = (a * new_seed + b) % M\n",
    "        out.append(new_seed / M)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem1_uniform(generator=None, period = 1, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator and produces samples from the uniform [0,1] distribution according\n",
    "    to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of type generator(size,seed) and produces the same result as problem1_LCG, i.e. pseudo random numbers in the range {0,1,...,period-1}\n",
    "    period : the period of the generator\n",
    "    seed : the seed to be used in the generator provided\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the uniform pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    out_uniform = [ ]\n",
    "    random_numbers = generator(size = size, seed = seed)\n",
    "    out_uniform = [number / period for number in random_numbers]\n",
    "    \n",
    "    return out_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem1_accept_reject(uniformGenerator=None, n_iterations=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator that produces uniform pseudo random [0,1] numbers \n",
    "    and produces samples from (pi/2)*abs(sin(x*2*pi)) using an Accept-Reject\n",
    "    sampler with the uniform distribution as the proposal distribution.\n",
    "    Runs n_iterations\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of the type generator(size,seed) that produces uniform pseudo random\n",
    "    numbers from [0,1]\n",
    "    seed : the seed to be used in the generator provided\n",
    "    n_iterations : an integer denoting how many attempts should be made in the accept-reject sampler\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the pseudo random numbers with the specified distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    XXX\n",
    "    \n",
    "    return XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "def problem1_accept_reject(uniformGenerator=None, n_iterations=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator that produces uniform pseudo random [0,1] numbers \n",
    "    and produces samples from (pi/2)*abs(sin(x*2*pi)) using an Accept-Reject\n",
    "    sampler with the uniform distribution as the proposal distribution.\n",
    "    Runs n_iterations\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of the type generator(size,seed) that produces uniform pseudo random\n",
    "    numbers from [0,1]\n",
    "    seed : the seed to be used in the generator provided\n",
    "    n_iterations : an integer denoting how many attempts should be made in the accept-reject sampler\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the pseudo random numbers with the specified distribution\n",
    "    \"\"\"\n",
    "    now_seed = seed\n",
    "    problem3_samples = []\n",
    "    M = np.pi / 2  # The bound for the accept-reject criterion\n",
    "\n",
    "    while len(problem3_samples) < n_iterations:\n",
    "        x = uniformGenerator(size=1, seed=now_seed)[0]\n",
    "        \n",
    "        # Calculate the probability of accepting the sample\n",
    "        f_x = (np.pi / 2) * abs(np.sin(x * 2 * np.pi))\n",
    "\n",
    "        # Use the next seed value for the acceptance check\n",
    "        now_seed += 1\n",
    "        u = uniformGenerator(size=1, seed=now_seed)[0]  # Uniform random number for acceptance\n",
    "\n",
    "        # Increment the seed for the next iteration\n",
    "        now_seed += 1\n",
    "        \n",
    "        # Accept the sample with probability f(x)/(M*g(x))\n",
    "        if u < f_x / M:\n",
    "            problem3_samples.append(x)\n",
    "    \n",
    "    return problem3_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 2, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCG output: [0.23645552527159452, 0.3692706737201661, 0.5042420323006809, 0.7048832636792213, 0.05054362863302231, 0.3695183543022722, 0.7747629624791443, 0.556188570568338, 0.0164932357147336, 0.6392460397910327]\n",
      "Uniform sampler [1.1010818428899838e-10, 1.719550572895287e-10, 2.348059938758057e-10, 3.282368479665468e-10, 2.3536211174457478e-11, 1.7207039254823336e-10, 3.6077711846639604e-10, 2.5899548575670367e-10, 7.68026137479283e-12, 2.976721337954666e-10]\n",
      "Accept-Reject sampler [1.1010818428899838e-10, 1.1046912061322967e-10, 1.1083005693746095e-10, 1.1119099326169224e-10, 1.1155192958592353e-10, 1.1191286591015481e-10, 1.122738022343861e-10, 1.1263473855861739e-10, 1.1299567488284867e-10, 1.1335661120707996e-10, 1.1371754753131125e-10, 1.1407848385554253e-10, 1.1443942017977382e-10, 1.1480035650400511e-10, 1.151612928282364e-10, 1.1552222915246768e-10, 1.1588316547669897e-10, 1.1624410180093026e-10, 1.1660503812516154e-10, 1.1696597444939283e-10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If you managed to solve all three parts you can test the following code to see if it runs\n",
    "# you have to change the period to match your LCG though, this is marked as XXX.\n",
    "# It is a very good idea to check these things using the histogram function in sagemath\n",
    "# try with a larger number of samples, up to 10000 should run\n",
    "\n",
    "print(\"LCG output: %s\" % problem1_LCG(size=10, seed = 1))\n",
    "\n",
    "period = 2147483648\n",
    "\n",
    "print(\"Uniform sampler %s\" % problem1_uniform(generator=problem1_LCG, period = period, size=10, seed=1))\n",
    "\n",
    "uniform_sampler = lambda size,seed: problem1_uniform(generator=problem1_LCG, period = period, size=size, seed=seed)\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem1_accept_reject(uniformGenerator = uniform_sampler,n_iterations=20,seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept-Reject sampler [0.23796462709189137, 0.32383276483316237, 0.2590084917154736, 0.6484972199788831, 0.6820045605879779, 0.20985124453651727, 0.38102068999577143, 0.2718754143840908, 0.35184625582788265, 0.243517762709337, 0.22418547484732643, 0.414743999308679, 0.6842409524120733, 0.32375334582076565, 0.27981547357298786, 0.799115369116727, 0.14533616183328069, 0.1995887063541001, 0.14595480067964695, 0.08109066462388448]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If however you did not manage to implement either part 1 or part 2 but still want to check part 3, you can run the code below\n",
    "\n",
    "def testUniformGenerator(size,seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    return [random.uniform(0,1) for s in range(size)]\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem1_accept_reject(uniformGenerator=testUniformGenerator, n_iterations=20, seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Markovian travel\n",
    "\n",
    "The dataset `Travel Dataset - Datathon 2019` is a simulated dataset designed to mimic real corporate travel systems -- focusing on flights and hotels. The file is at `data/flights.csv`, i.e. you can use the path `data/flights.csv` from the notebook to access the file.\n",
    "\n",
    "1. [2p] In the first code-box \n",
    "    1. Load the csv from file `data/flights.csv`\n",
    "    2. Fill in the value of the variables as specified by their names.\n",
    "2. [2p] In the second code-box your goal is to estimate a Markov chain transition matrix for the travels of these users. For example, if we enumerate the cities according to alphabetical order, the first city `'Aracaju (SE)'` would correspond to $0$. Each row of the file corresponds to one flight, i.e. it has a starting city and an ending city. We model this as a stationary Markov chain, i.e. each user's travel trajectory is a realization of the Markov chain, $X_t$. Here, $X_t$ is the current city the user is at, at step $t$, and $X_{t+1}$ is the city the user travels to at the next time step. This means that to each row in the file there is a corresponding pair $(X_{t},X_{t+1})$. The stationarity assumption gives that for all $t$ there is a transition density $p$ such that $P(X_{t+1} = y | X_t = x) = p(x,y)$ (for all $x,y$). The transition matrix should be `n_cities` x `n_citites` in size.\n",
    "3. [2p] Use the transition matrix to compute out the stationary distribution.\n",
    "4. [2p] Given that we start in 'Aracaju (SE)' what is the probability that after 3 steps we will be back in 'Aracaju (SE)'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "1335\n",
      "271888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import csv\n",
    "data = pd.read_csv(\"data/flights.csv\")\n",
    "number_of_cities = data['from'].nunique() + data['to'].nunique()\n",
    "print(number_of_cities)\n",
    "number_of_userCodes = data['userCode'].nunique()\n",
    "print(number_of_userCodes)\n",
    "number_of_observations = len(data)\n",
    "print(number_of_observations)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This is a very useful function that you can use for part 2. You have seen this before when parsing the\n",
    "# pride and prejudice book.\n",
    "\n",
    "def makeFreqDict(myDataList):\n",
    "    '''Make a frequency mapping out of a list of data.\n",
    "\n",
    "    Param myDataList, a list of data.\n",
    "    Return a dictionary mapping each unique data value to its frequency count.'''\n",
    "\n",
    "    freqDict = {} # start with an empty dictionary\n",
    "\n",
    "    for res in myDataList:\n",
    "        if res in freqDict: # the data value already exists as a key\n",
    "                freqDict[res] = freqDict[res] + 1 # add 1 to the count using sage integers\n",
    "        else: # the data value does not exist as a key value\n",
    "            freqDict[res] = 1 # add a new key-value pair for this new data value, frequency 1\n",
    "\n",
    "    return freqDict # return the dictionary created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.12983559 0.14487965 0.23218891 0.1057651  0.13120567\n",
      "  0.07570385 0.07839029 0.10203095]\n",
      " [0.15702265 0.         0.14675591 0.25273726 0.09704669 0.12417557\n",
      "  0.06478443 0.06527178 0.09220572]\n",
      " [0.15520318 0.12999309 0.         0.23751007 0.1019627  0.12979164\n",
      "  0.0695004  0.07252216 0.10351675]\n",
      " [0.15079296 0.1357189  0.14398869 0.         0.11705079 0.13275294\n",
      "  0.10131375 0.10119162 0.11719036]\n",
      " [0.16544797 0.1255253  0.14889057 0.28193814 0.         0.12161708\n",
      "  0.03992268 0.0389141  0.07774416]\n",
      " [0.16023622 0.1253937  0.14796588 0.24963911 0.09494751 0.\n",
      "  0.06223753 0.06404199 0.09553806]\n",
      " [0.16758846 0.1185846  0.14362177 0.34534642 0.05649718 0.11281594\n",
      "  0.         0.         0.05554564]\n",
      " [0.17060337 0.1174579  0.14733396 0.33910196 0.05413938 0.11412535\n",
      "  0.         0.         0.05723807]\n",
      " [0.1607619  0.12012698 0.15225397 0.28431746 0.07830688 0.12325926\n",
      "  0.03953439 0.04143915 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "cities = data['from'].tolist()+data['to'].tolist()\n",
    "unique_cities = sorted(set(cities)) # The unique cities\n",
    "n_cities = len(unique_cities) # The number of unique citites\n",
    "\n",
    "# Count the different transitions\n",
    "transitions = list(zip(data['from'], data['to'])) # A list containing tuples ex: ('Aracaju (SE)','Rio de Janeiro (RJ)') of all transitions in the text\n",
    "transition_counts = Counter(transitions) # A dictionary that counts the number of each transition \n",
    "# ex: ('Aracaju (SE)','Rio de Janeiro (RJ)'):4\n",
    "indexToCity = {i: city for city,i in enumerate(unique_cities)} # A dictionary that maps the n-1 number to the n:th unique_city,\n",
    "# ex: 0:'Aracaju (SE)'\n",
    "cityToIndex = {city : i for i ,city in enumerate(unique_cities) } # The inverse function of indexToWord, \n",
    "# ex: 'Aracaju (SE)':0\n",
    "\n",
    "# Part 3, finding the maximum likelihood estimate of the transition matrix\n",
    "\n",
    "transition_matrix = np.zeros((n_cities,n_cities)) # a numpy array of size (n_cities,n_cities)\n",
    "# Populate the transition matrix\n",
    "for (start, end), count in transition_counts.items():\n",
    "    start_index = cityToIndex[start]\n",
    "    end_index = cityToIndex[end]\n",
    "    transition_matrix[start_index, end_index] = count\n",
    "\n",
    "# Convert counts to probabilities\n",
    "for i in range(n_cities):\n",
    "    row_sum = np.sum(transition_matrix[i, :])\n",
    "    if row_sum > 0:\n",
    "        transition_matrix[i, :] /= row_sum\n",
    "\n",
    "# Ensure there are no NaNs in the transition matrix\n",
    "transition_matrix = np.nan_to_num(transition_matrix)\n",
    "# The transition matrix should be ordered in such a way that\n",
    "# p_{'Aracaju (SE)','Rio de Janeiro (RJ)'} = transition_matrix[cityToIndex['Aracaju (SE)'],cityToIndex['Rio de Janeiro (RJ)']]\n",
    "# and represents the probability of travelling Aracaju (SE)->Rio de Janeiro (RJ)\n",
    "print(transition_matrix)\n",
    "# Make sure that the transition_matrix does not contain np.nan from division by zero for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This should be a numpy array of length n_cities which sums to 1 and is all positive\n",
    "\n",
    "# This should be a numpy array of length n_cities which sums to 1 and is all positive\n",
    "# Compute the stationary distribution\n",
    "eigenvalues, eigenvectors = np.linalg.eig(transition_matrix.T)\n",
    "stationary_distribution_index = np.argmin(np.abs(eigenvalues - 1))\n",
    "stationary_distribution = np.real(eigenvectors[:, stationary_distribution_index]).astype(float)\n",
    "\n",
    "# Normalize the stationary distribution\n",
    "stationary_distribution /= stationary_distribution.sum()\n",
    "\n",
    "# Ensuring the distribution is valid (non-negative and sums to 1)\n",
    "stationary_distribution = np.clip(stationary_distribution, 0, None)\n",
    "stationary_distribution /= stationary_distribution.sum()\n",
    "\n",
    "#stationary_distribution.shape, stationary_distribution[:5]  # Displaying the shape and a part of the distribution\n",
    "\n",
    "stationary_distribution_problem2 = stationary_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13331717737273133"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Compute the return probability for part 3 of PROBLEM 2\n",
    "aracaju_index = cityToIndex['Aracaju (SE)']\n",
    "\n",
    "# Compute the transition matrix raised to the power of 3\n",
    "transition_matrix_3_steps = np.linalg.matrix_power(transition_matrix, 3)\n",
    "\n",
    "# Probability of being back in 'Aracaju (SE)' after 3 steps\n",
    "return_probability_problem2 = transition_matrix_3_steps[aracaju_index, aracaju_index]\n",
    "return_probability_problem2\n",
    "#return_probability_problem2 = XXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 2, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m current_pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(start)\n\u001b[1;32m     12\u001b[0m current_pos[random_word_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mindexToCity\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrandom_word_index\u001b[49m\u001b[43m]\u001b[49m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m->\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m current_pos \u001b[38;5;241m=\u001b[39m (current_pos\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@transition_matrix\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Once you have created all your functions, you can make a small test here to see\n",
    "# what would be generated from your model.\n",
    "import numpy as np\n",
    "\n",
    "start = np.zeros(shape=(n_cities,1))\n",
    "start[cityToIndex['Aracaju (SE)'],0] = 1\n",
    "\n",
    "current_pos = start\n",
    "for i in range(10):\n",
    "    random_word_index = np.random.choice(range(n_cities),p=current_pos.reshape(-1))\n",
    "    current_pos = np.zeros_like(start)\n",
    "    current_pos[random_word_index] = 1\n",
    "    print(indexToCity[random_word_index],end='->')\n",
    "    current_pos = (current_pos.T@transition_matrix).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "4"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 3\n",
    "Maximum Points = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "4"
   },
   "source": [
    "\n",
    "\n",
    "Derive the maximum likelihood estimate for $n$ IID samples from a random variable with the following probability density function:\n",
    "$$\n",
    "f(x; \\lambda) = \\frac{1}{24} \\lambda^5 x^4 \\exp(-\\lambda x), \\qquad \\text{ where, } \\lambda>0, x > 0\n",
    "$$\n",
    "\n",
    "You can solve the MLe by hand (using pencil paper or using key-strokes). Present your solution as the return value of a function called `def MLeForAssignment2Problem3(x)`, where `x` is a list of $n$ input data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive the maximum likelihood estimate (MLE) for \\( n \\) IID samples from the given probability density function (PDF), we follow these steps:\n",
    "\n",
    "1. **Write Down the Likelihood Function**: The likelihood function \\( L(\\lambda) \\) is the product of the PDFs of all \\( n \\) samples.\n",
    "\n",
    "2. **Take the Logarithm to Obtain the Log-Likelihood**: It is easier to work with the sum rather than the product.\n",
    "\n",
    "3. **Differentiate the Log-Likelihood with Respect to \\( \\lambda \\)**: This gives us the score function.\n",
    "\n",
    "4. **Solve for \\( \\lambda \\) in the Equation \\( \\frac{d}{d\\lambda} \\log L(\\lambda) = 0 \\)**: This will give us the MLE for \\( \\lambda \\).\n",
    "\n",
    "Given the PDF \\( f(x; \\lambda) = \\frac{1}{24} \\lambda^5 x^4 \\exp(-\\lambda x) \\), let's perform these steps:\n",
    "\n",
    "1. Likelihood Function:\n",
    "   \\[ L(\\lambda) = \\prod_{i=1}^{n} \\frac{1}{24} \\lambda^5 x_i^4 \\exp(-\\lambda x_i) \\]\n",
    "\n",
    "2. Log-Likelihood Function:\n",
    "   \\[ \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( \\log \\frac{1}{24} + 5 \\log \\lambda + 4 \\log x_i - \\lambda x_i \\right) \\]\n",
    "\n",
    "3. Differentiating Log-Likelihood:\n",
    "   \\[ \\frac{d}{d\\lambda} \\log L(\\lambda) = \\sum_{i=1}^{n} \\left( \\frac{5}{\\lambda} - x_i \\right) \\]\n",
    "\n",
    "4. Setting the Derivative to Zero:\n",
    "   \\[ \\sum_{i=1}^{n} \\left( \\frac{5}{\\lambda} - x_i \\right) = 0 \\]\n",
    "\n",
    "Solving for \\( \\lambda \\):\n",
    "\\[ \\frac{5n}{\\lambda} = \\sum_{i=1}^{n} x_i \\]\n",
    "\\[ \\lambda = \\frac{5n}{\\sum_{i=1}^{n} x_i} \\]\n",
    "\n",
    "Now, let's write the `MLeForAssignment2Problem3` function:\n",
    "\n",
    "```python\n",
    "def MLeForAssignment2Problem3(x):\n",
    "    '''Calculate the Maximum Likelihood Estimate (MLE) for the given samples x\n",
    "    from a distribution with PDF f(x; lambda) = (1/24) * lambda^5 * x^4 * exp(-lambda * x)'''\n",
    "    n = len(x)  # Number of samples\n",
    "    sum_x = sum(x)  # Sum of all samples\n",
    "    mle_lambda = 5 * n / sum_x  # MLE for lambda\n",
    "    return mle_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# do not change the name of the function, just replace XXX with the appropriate expressions for the MLe\n",
    "def MLeForAssignment2Problem3(x):\n",
    "    '''Calculate the Maximum Likelihood Estimate (MLE) for the given samples x\n",
    "    from a distribution with PDF f(x; lambda) = (1/24) * lambda^5 * x^4 * exp(-lambda * x)'''\n",
    "    n = len(x)  # Number of samples\n",
    "    sum_x = sum(x)  # Sum of all samples\n",
    "    mle_lambda = 5 * n / sum_x  # MLE for lambda\n",
    "    return mle_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "4"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 4\n",
    "Maximum Points = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "4"
   },
   "source": [
    "\n",
    "Use the **Multi-dimensional Constrained Optimisation** example (in `07-Optimization.ipynb`) to numerically find the MLe for the mean and variance parameter based on `normallySimulatedDataSamples`, an array obtained by a specific simulation of $30$ IID samples from the $Normal(10,2)$ random variable.\n",
    "\n",
    "Recall that $Normal(\\mu, \\sigma^2)$ RV has the probability density function given by:\n",
    "\n",
    "$$\n",
    "f(x ;\\mu, \\sigma) = \\displaystyle\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(\\frac{-1}{2\\sigma^2}(x-\\mu)^2\\right)\n",
    "$$\n",
    "\n",
    "The two parameters, $\\mu \\in \\mathbb{R} := (-\\infty,\\infty)$ and $\\sigma \\in (0,\\infty)$, are sometimes referred to as the location and scale parameters.\n",
    "\n",
    "You know that the log likelihood function for $n$ IID samples from a Normal RV with parameters $\\mu$ and $\\sigma$ simply follows from $\\sum_{i=1}^n \\log(f(x_i; \\mu,\\sigma))$, based on the IID assumption. \n",
    "\n",
    "NOTE: When setting bounding boxes for $\\mu$ and $\\sigma$ try to start with some guesses like $[-20,20]$ and $[0.1,5.0]$ and make it larger if the solution is at the boundary. Making the left bounding-point for $\\sigma$ too close to $0.0$ will cause division by zero Warnings. Other numerical instabilities can happen in such iterative numerical solutions to the MLe. You need to be patient and learn by trial-and-error. You will see the mathematical theory in more details in a future course in scientific computing/optimisation. So don't worry too much now except learning to use it for our problems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 58.631387282380196\n",
       "        x: [ 9.269e+00  1.708e+00]\n",
       "      nit: 12\n",
       "      jac: [ 1.634e-05  4.974e-06]\n",
       "     nfev: 69\n",
       "     njev: 23\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "\n",
    "# Simulated data\n",
    "np.random.seed(123456)\n",
    "normallySimulatedDataSamples = np.random.normal(10, 2, 30)\n",
    "\n",
    "def negLogLklOfIIDNormalSamples(parameters):\n",
    "    '''return the negative log(likelihood) of normallySimulatedDataSamples with mean and var parameters'''\n",
    "    mu_param, sigma_param = parameters\n",
    "    n = len(normallySimulatedDataSamples)\n",
    "    sum_squared_diff = np.sum((normallySimulatedDataSamples - mu_param) ** 2)\n",
    "    log_likelihood = -n / 2 * np.log(2 * np.pi) - n * np.log(sigma_param) - sum_squared_diff / (2 * sigma_param ** 2)\n",
    "    return -log_likelihood\n",
    "\n",
    "# Bounds and initial guess\n",
    "parameter_bounding_box = ((-20, 20), (0.1, 5.0))\n",
    "initial_arguments = np.array([0.0, 1.0])\n",
    "\n",
    "# Minimizing the negative log likelihood\n",
    "result_Ass2Prob4 = optimize.minimize(negLogLklOfIIDNormalSamples, initial_arguments, bounds=parameter_bounding_box)\n",
    "result_Ass2Prob4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "lx_assignment_number": 2,
  "lx_course_instance": "2022",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
