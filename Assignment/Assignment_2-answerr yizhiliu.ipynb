{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 2 for Course 1MS041\n",
    "Make         sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline         and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 1\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "A courier company operates a fleet of delivery trucks that make deliveries to different parts of the city. The trucks are equipped with GPS tracking devices that record the location of each truck at regular intervals. The locations are divided into three regions: downtown, the suburbs, and the countryside. The following table shows the probabilities of a truck transitioning between these regions at each time step:\n",
    "\n",
    "| Current region | Probability of transitioning to downtown | Probability of transitioning to the suburbs | Probability of transitioning to the countryside |\n",
    "|----------------|--------------------------------------------|-----------------------------------------------|------------------------------------------------|\n",
    "| Downtown       | 0.3                                      | 0.4                                           | 0.3                                            |\n",
    "| Suburbs        | 0.2                                      | 0.5                                           | 0.3                                            |\n",
    "| Countryside    | 0.4                                      | 0.3                                           | 0.3                                            |\n",
    "\n",
    "1. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region after two time steps? [1.5p]\n",
    "2. If a truck is currently in the suburbs, what is the probability that it will be in the downtown region **the first time** after two time steps? [1.5p]\n",
    "3. Is this Markov chain irreducible? [1.5p]\n",
    "4. What is the stationary distribution? [1.5p]\n",
    "5. Advanced question: What is the expected number of steps until the first time one enters the downtown region having started in the suburbs region. Hint: to get within 1 decimal point, it is enough to compute the probabilities for hitting times below 30. [2p]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "\n",
    "# Fill in the answer to part 1 below as a decimal number\n",
    "problem1_p1 = 0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "\n",
    "# Fill in the answer to part 2 below as a decimal number\n",
    "problem1_p2 = 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3\n",
    "\n",
    "# Fill in the answer to part 3 below as a boolean\n",
    "problem1_irreducible = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# Fill in the answer to part 4 below\n",
    "# the answer should be a numpy array of length 3\n",
    "# make sure that the entries sums to 1!\n",
    "problem1_stationary =  [0.28888889,0.41111111,0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 5\n",
    "\n",
    "# Fill in the answer to part 5 below\n",
    "# That is, the expected number of steps as a decimal number\n",
    "problem1_ET = 3.846"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 2\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "A healthcare organization is interested in understanding the relationship between the number of visits to the doctors office and certain patient characteristics. \n",
    "They have collected data on the number of visits (for a year) for a sample of patients and have included the following variables\n",
    "\n",
    "* ofp : number of physician office visits\n",
    "* ofnp : number of nonphysician office visits\n",
    "* opp : number of physician outpatient visits\n",
    "* opnp : number of nonphysician outpatient visits\n",
    "* emr : number of emergency room visits\n",
    "* hosp : number of hospitalizations\n",
    "* exclhlth : the person is of excellent health (self-perceived)\n",
    "* poorhealth : the person is of poor health (self-perceived)\n",
    "* numchron : number of chronic conditions\n",
    "* adldiff : the person has a condition that limits activities of daily living ?\n",
    "* noreast : the person is from the north east region\n",
    "* midwest : the person is from the midwest region\n",
    "* west : the person is from the west region\n",
    "* age : age in years (divided by 10)\n",
    "* male : is the person male ?\n",
    "* married : is the person married ?\n",
    "* school : number of years of education\n",
    "* faminc : family income in 10000$\n",
    "* employed : is the person employed ?\n",
    "* privins : is the person covered by private health insurance?\n",
    "* medicaid : is the person covered by medicaid ?\n",
    "\n",
    "Decide which patient features are resonable to use to predict the target \"number of physician office visits\". Hint: should we really use the \"ofnp\" etc variables?\n",
    "\n",
    "Since the target variable is counts, a reasonable loss function is to consider the target variable as Poisson distributed where the parameter follows $\\lambda = \\exp(\\alpha \\cdot x + \\beta)$ where $\\alpha$ is a vector (slope) and $\\beta$ is a number (intercept). That is, the parameter is the exponential of a linear function. The reason we chose this as our parameter, is that it is always positive which is when the Poisson distribution is defined. To be specific we make the following assumption about our conditional density of $Y \\mid X$,\n",
    "$$\n",
    "    f_{Y \\mid X} (y,x) = \\frac{\\lambda^{y} e^{-\\lambda}}{y !}, \\quad \\lambda(x) = \\exp(\\alpha \\cdot x + \\beta).\n",
    "$$\n",
    "\n",
    "Recall from the lecture notes, (4.2) that in this case we should consider the log-loss (entropy) and that according to (4.2.1 Maximum Likelihood and regression) we can consider the conditional log-likelihood. Follow the steps of Example 1 and Example 2 in section (4.2) to derive the loss that needs to be minimized.\n",
    "\n",
    "Hint: when taking the log of the conditional density you will find that the term that contains the $y!$ does not depend on $\\lambda$ and as such does not depend on $\\alpha,\\beta$, it can thus be discarded. This will be essential due to numerical issues with factorials.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Load the file `data/visits_clean.csv`, follow the instructions in the code cell of how this should happen [1.5p]\n",
    "2. Create the `problem2_X` and the `problem2_y` as numpy arrays with `problem2_X` being the features and `problem2_y` being the target. Do the standard train-test split with 80% training data and 20% testing data. Store these in the variables defined in the cells. [1.5p]\n",
    "3. Implement $loss$ inside the class `PoissonRegression` by writing down the loss to be minimized, I have provided a formula for the $\\lambda$ that you can use. [1.5p]\n",
    "4. Now use the `PoissonRegression` class to train a Poisson regression model on the training data. [1.5p]\n",
    "5. Compute the mean absolute error of your prediction on the test set and use Hoeffdings inequality to produce a 95\\% confidence interval for the mean absolute error. We can make the assumption that the error is bounded by 70 for simplicity. [2p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3524, 20) (3524,)\n",
      " message: Optimization terminated successfully.\n",
      " success: True\n",
      "  status: 0\n",
      "     fun: 831.3003007886315\n",
      "       x: [ 2.080e+00  2.514e-01 ...  2.022e-01 -3.583e+00]\n",
      "     nit: 412\n",
      "     jac: [ 0.000e+00  7.629e-06 ... -7.629e-06  0.000e+00]\n",
      "    nfev: 17712\n",
      "    njev: 805\n"
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "\n",
    "# As in assignment 1 we will load the header into header and data into data\n",
    "# this time you will have to parse the data such that each data entry is a float\n",
    "# and that the problem2_data is a numpy array of shape (n_samples,n_columns)\n",
    "# where n_columns is the number of columns and should have the same length as\n",
    "# the list of strings header. n_samples is how many rows of data we had.\n",
    "# If you cannot find the file, check the starting package as it should be updated\n",
    "# if not, go to the github repo and pull it\n",
    "#合理的患者特征包括exclhlth, poorhealth, numchron, adldiff, age, male, married, school, faminc, employed, privins, medicaid，\n",
    "#不合理的特征包括ofnp, opp, opnp, emr, hosp，这些特征本身就是就诊次数的不同类型，不能用来预测ofp。\n",
    "#使用numpy库加载数据文件，使用train_test_split函数划分训练集和测试集，使用PoissonRegression类定义模型并拟合训练数据，使用predict函数预测测试数据，并使用mean_absolute_error函数计算误差和置信区间。\n",
    "# The autograder does not accept pandas as a solution to this problem.\n",
    "# data/visits_clean.csv\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import scipy.special\n",
    "data_row=[]\n",
    "# correct_feature=[\"ofp\",\"exclhlth\", \"poorhlth\", \"numchron\", \"adldiff\", \"age\", \"male\", \"married\", \"school\", \"faminc\"\\\n",
    "    # , \"employed\", \"privins\", \"medicaid\"]\n",
    "# correct_feature1=['ofp','numchron','adldiff','noreast','midwest','west','age','male',\n",
    "#                  'married','school','faminc','employed','privins','medicaid']\n",
    "problem2_header=[]\n",
    "# with open(\"data/visits_clean.csv\",\"r\") as file:\n",
    "with open(r\"data/visits_clean.csv\",\"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    problem2_header = next(reader)[0].strip().split(\" \")\n",
    "    \n",
    "    #numpy.genfromtxt(fname, dtype=<type 'float'>, comments='#', delimiter=None, skip_header=0, skip_footer=0, converters=None, missing_values=None, filling_values=None, usecols=None, names=None, excludelist=None, deletechars=None, replace_space='_', autostrip=False, case_sensitive=True, defaultfmt='f%i', unpack=None, usemask=False, loose=True, invalid_raise=True, max_rows=None)\n",
    "    # for row in reader:\n",
    "    #     data_row=[float(eval(value)) for value in row]\n",
    "    #     data_rows.append(data_row)\n",
    "\n",
    "# feature_index=[problem2_header.index(x) for x in correct_feature]\n",
    "# geography_index=[problem2_header.index(x) for x in [\"noreast\",\"midwest\",\"west\"]]\n",
    "\n",
    "data_rows=np.genfromtxt(r\"data/visits_clean.csv\",dtype=float,delimiter=\" \",skip_header=1)\n",
    "# data_rows=np.genfromtxt(r\"data/visits_clean.csv\",dtype=float,delimiter=\" \",skip_header=1,\\\n",
    "#                usecols=feature_index)\n",
    "# geography=np.genfromtxt(r\"data/visits_clean.csv\",dtype=float,delimiter=\" \",skip_header=1,\\\n",
    "#                 usecols=geography_index)\n",
    "# #problem2_header = [\"\"] #List of strings\n",
    "\n",
    "#+1dataset,combine three geography features in to one onehotcode for test Xtrain \n",
    "problem2_data = np.array(data_rows) #A numpy array of shape n_samples n_columns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(problem2_data)\n",
    "problem2_data = scaler.transform(problem2_data) \n",
    "\n",
    "\n",
    "geography_new=np.zeros((len(geography),1))\n",
    "for i,num in zip(geography,range(len(geography))):\n",
    "   \n",
    "    if i[0]==1:\n",
    "        geography_new[num]=1\n",
    "     \n",
    "    elif i[1]==1:\n",
    "        geography_new[num]=2\n",
    "  \n",
    "    elif i[2]==1:\n",
    "        geography_new[num]=3\n",
    "       \n",
    "    else:\n",
    "        geography_new[num]=4\n",
    "        \n",
    "    \n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit(geography_new)\n",
    "geography_onehot=encoder.transform(geography_new).toarray()\n",
    "# problem2_data=np.hstack((problem2_data,geography_onehot))\n",
    "# Part 2\n",
    "\n",
    "# Fill in your X and y below +3数据集，仅用于测试总数据集形状\n",
    "# feature_index1=[problem2_header.index(x) for x in correct_feature]\n",
    "# data_rows1=np.genfromtxt(r\"data/visits_clean.csv\",dtype=float,delimiter=\" \",skip_header=1,\\\n",
    "#                usecols=feature_index1)\n",
    "# problem2_data1 = np.array(data_rows)\n",
    "problem2_X = problem2_data[[],1:]\n",
    "problem2_y = problem2_data[[],0]\n",
    "\n",
    "indices = np.arange(problem2_data.shape[0])\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_ratio=0.8\n",
    "total_samples=problem2_data.shape[0]\n",
    "train_samples=int(total_samples*train_ratio)\n",
    "\n",
    "problem2_X_train = problem2_data[indices[:train_samples],1:]\n",
    "problem2_y_train = problem2_data[indices[:train_samples],0]\n",
    "\n",
    "\n",
    "problem2_X_test = problem2_data[indices[train_samples:], 1:]\n",
    "problem2_y_test = problem2_data[indices[train_samples:], 0]\n",
    "# Split the data problem2_data into train and randomly using for instance\n",
    "# np.random.shuffle indices and indexing the first 80% as the train data\n",
    "# keep the train size as 0.8 rounded up to the nearest integer sample\n",
    "\n",
    "print(problem2_X_train.shape,problem2_y_train.shape)\n",
    "\n",
    "# Part 3\n",
    "\n",
    "# Fill in the function loss below\n",
    "\n",
    "class PoissonRegression(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        # The parameter lambda for the given X and the proposed values \n",
    "        # of the coefficients, here coeff[:-1] represent alpha \n",
    "        # and coeff[-1] represent beta\n",
    "        lam = np.exp(np.dot(X, coeffs[:-1]) + coeffs[-1])\n",
    "\n",
    "        # use the Y variable that is available here to define \n",
    "        # the loss function, return the value of the loss for \n",
    "        # this Y and for this parameter lam defined above\n",
    "        neg_log_likelihood = -np.sum(Y * np.log(lam) - lam)\n",
    "        # neg_log_likelihood=-np.sum(Y*np.log(lam)-lam-np.log(scipy.special.factorial(Y)))\n",
    "        return neg_log_likelihood\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "\n",
    "\n",
    "        #Use the loss above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        #this is prepared for you below\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1) # initial guess as 0\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            return np.exp(np.dot(X,self.coeffs[:-1])+self.coeffs[-1])\n",
    "        \n",
    "# Part 4\n",
    "\n",
    "# Initialize your PoissonRegression model\n",
    "problem2_model = PoissonRegression()\n",
    "\n",
    "# Fit your initialized model on the training data\n",
    "problem2_model.fit(problem2_X_train,problem2_y_train)\n",
    "\n",
    "# This is to make sure that everything went well, \n",
    "# check that success is True\n",
    "print(problem2_model.result)\n",
    "\n",
    "\n",
    "# Part 5\n",
    "\n",
    "# Put the computed mean absolute error in the variable below\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Assuming you have predictions and actual values for the test data\n",
    "predictions = problem2_model.predict(problem2_X_test)\n",
    "actual_values = problem2_y_test\n",
    "\n",
    "# Calculate MAE\n",
    "MAE = mean_absolute_error(actual_values, predictions)\n",
    "\n",
    "problem2_metric = MAE\n",
    "# Put a confidence interval in the variable below by using Hoeffdings inequality using the bounds\n",
    "# a = 0, b=70 (roughly 5 days between visits as minimum)\n",
    "# the variable should contain a tuple representing the confidence interval of the form (l_edge,r_edge)\n",
    "\n",
    "# Calculate the confidence interval using Hoeffding's inequality\n",
    "a = 0  # Lower bound\n",
    "b = 70  # Upper bound\n",
    "\n",
    "# Calculate the confidence interval\n",
    "# epsilon = np.sqrt((1 / (2 * len(problem2_X_test)) * np.log(2 / 0.05))) \n",
    "epsilon =np.sqrt((b - a) ** 2 * np.log(2 / 0.05) / (2 * len(problem2_y_test)))\n",
    "l_edge = max(MAE - epsilon,a)\n",
    "r_edge =min(MAE + epsilon,b)\n",
    " \n",
    "# Create a tuple representing the confidence interval\n",
    "problem2_interval = (l_edge, r_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04569161802251758"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.linear_model import PoissonRegressor\n",
    "\n",
    "# # 定义模型\n",
    "# model = PoissonRegressor()\n",
    "\n",
    "# # 训练模型\n",
    "# model.fit(problem2_X_train, problem2_y_train)\n",
    "\n",
    "# # 预测结果\n",
    "# y_pred = model.predict(problem2_X_test)\n",
    "# # 打印参数\n",
    "# print(model.coef_)\n",
    "\n",
    "# # 打印\n",
    "# MAE=mean_absolute_error(problem2_y_test,y_pred)\n",
    "# MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "## Assignment 2, PROBLEM 3\n",
    "Maximum Points = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "\n",
    "## Random variable generation and transformation\n",
    "\n",
    "The purpose of this problem is to show that you can implement your own sampler, this will be built in the following three steps:\n",
    "\n",
    "1. [2p] Implement a Linear Congruential Generator where you tested out a good combination (a large $M$ with $a,b$ satisfying the Hull-Dobell (Thm 6.8)) of parameters. Follow the instructions in the code block.\n",
    "2. [2p] Using a generator construct random numbers from the uniform $[0,1]$ distribution.\n",
    "3. [4p] Using a uniform $[0,1]$ random generator, generate samples from \n",
    "\n",
    "$$p_0(x) = \\frac{\\pi}{2}|\\sin(2\\pi x)|, \\quad x \\in [0,1] \\enspace .$$\n",
    "\n",
    "Using the **Accept-Reject** sampler (**Algorithm 1** in TFDS notes) with sampling density given by the uniform $[0,1]$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem3_LCG(size=None, seed=0):\n",
    "    \"\"\"\n",
    "    A linear congruential generator that generates pseudo random numbers according to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    size : an integer denoting how many samples should be produced\n",
    "    seed : the starting point of the LCG, i.e., u0 in the notes.\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    out : a list of the pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    a = 1664525\n",
    "    b = 1013904223\n",
    "    M = 2**32  # A large M value\n",
    "    state = seed\n",
    "    \n",
    "    # Initialize the state (seed)\n",
    "    state = seed\n",
    "    \n",
    "    # List to hold the pseudorandom numbers\n",
    "    out = []\n",
    "    \n",
    "    # Generate pseudorandom numbers up to the specified size\n",
    "    for _ in range(size if size is not None else 1):\n",
    "        # Update the state using the LCG formula\n",
    "        state = (a * state + b) % M\n",
    "        # Append the state to the list after normalizing\n",
    "        out.append(state / M)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "\n",
    "def problem3_uniform(generator=None, period=1, size=None, seed=0):\n",
    "    \"\"\"\n",
    "    Takes a generator and produces samples from the uniform [0,1] distribution according\n",
    "    to size.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    generator : a function of type generator(size, seed) that produces pseudo random numbers\n",
    "                in the range {0,1,...,period-1}\n",
    "    period    : the period of the generator\n",
    "    seed      : the seed to be used in the generator provided\n",
    "    size      : an integer denoting how many samples should be produced\n",
    "    \n",
    "    Returns\n",
    "    --------------\n",
    "    out : a list of the uniform pseudo random numbers\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate pseudo random numbers with the given generator\n",
    "    random_numbers = generator(size=size, seed=seed)\n",
    "    \n",
    "    # Normalize these numbers to the range [0,1]\n",
    "    uniform_random_numbers = [number / period for number in random_numbers]\n",
    "    \n",
    "    return uniform_random_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [],
   "source": [
    "def problem3_accept_reject(uniformGenerator=None, n_iterations=None, seed=0):\n",
    "    # No need to set np.random.seed here since we're not using np.random directly\n",
    "    \n",
    "    # Initialize a variable to keep track of the current state.\n",
    "    current_seed = seed\n",
    "    samples = []\n",
    "    M = np.pi / 2  # The bound for the accept-reject criterion\n",
    "\n",
    "    while len(samples) < n_iterations:\n",
    "        # Sample from the uniform distribution using the provided generator\n",
    "        x = uniformGenerator(size=1, seed=current_seed)[0]\n",
    "        \n",
    "        # Calculate the probability of accepting the sample\n",
    "        f_x = (np.pi / 2) * abs(np.sin(x * 2 * np.pi))\n",
    "\n",
    "        # Use the next seed value for the acceptance check\n",
    "        current_seed += 1\n",
    "        u = uniformGenerator(size=1, seed=current_seed)[0]  # Uniform random number for acceptance\n",
    "\n",
    "        # Increment the seed for the next iteration\n",
    "        current_seed += 1\n",
    "        \n",
    "        # Accept the sample with probability f(x)/(M*g(x))\n",
    "        if u < f_x / M:\n",
    "            samples.append(x)\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# You can then call your function with the initial seed:\n",
    "print(\"Accept-Reject sampler %s\" % problem3_accept_reject(uniformGenerator=uniform_sampler, n_iterations=20, seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "source": [
    "---\n",
    "#### Local Test for Assignment 2, PROBLEM 3\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCG output: [7.826369259425611e-06, 0.13153778814316625, 0.7556053221950332, 0.4586501319234493, 0.5327672374121692, 0.21895918632809036, 0.04704461621448613, 0.678864716868319, 0.6792964058366122, 0.9346928959408276]\n",
      "Uniform sampler [3.644437185986921e-15, 6.125205578488219e-11, 3.51856147193764e-10, 2.1357561095479172e-10, 2.4808907772426417e-10, 1.0196081662087291e-10, 2.190685655753733e-11, 3.1612101811191066e-10, 3.163220389526963e-10, 4.3525029736388376e-10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"LCG output: %s\" % problem3_LCG(size=10, seed=1))\n",
    "\n",
    "# Set the period to the modulus used in your LCG (replace 2**31 - 1 with your modulus if different)\n",
    "period = 2**31 - 1\n",
    "\n",
    "# Print the output of the uniform sampler\n",
    "print(\"Uniform sampler %s\" % problem3_uniform(generator=problem3_LCG, period=period, size=10, seed=1))\n",
    "\n",
    "# Define the uniform_sampler function using a lambda expression\n",
    "uniform_sampler = lambda size, seed: problem3_uniform(generator=problem3_LCG, period=period, size=size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "2",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept-Reject sampler [0.34681819919543666, 0.6840807597768621, 0.7112329216829939, 0.4472134383484645, 0.4306555016160535, 0.7362574515465967, 0.8064626626086779, 0.3982697025447973, 0.9070912163239052, 0.09034095270802844, 0.7793670805766362, 0.30161521354562826, 0.3506308489160106, 0.742923087744433, 0.5808862932227294, 0.6420041783046236, 0.03564764807021392, 0.7818439804824748, 0.7938147365943296, 0.8392775084388612]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If however you did not manage to implement either part 1 or part 2 but still want to check part 3, you can run the code below\n",
    "\n",
    "def testUniformGenerator(size,seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    return [random.uniform(0,1) for s in range(size)]\n",
    "\n",
    "print(\"Accept-Reject sampler %s\" % problem3_accept_reject(uniformGenerator=testUniformGenerator, n_iterations=20, seed=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "lx_assignment_number": 2,
  "lx_course_instance": "2023",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
