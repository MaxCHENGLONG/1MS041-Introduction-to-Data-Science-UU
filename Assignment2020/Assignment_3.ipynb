{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# [Introduction to Data Science: A Comp-Math-Stat Approach](https://lamastex.github.io/scalable-data-science/as/2019/)\n",
    "## 1MS041, 2020 \n",
    "&copy;2020 Raazesh Sainudiin, Benny Avelin. [Attribution 4.0 International (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Assignment 3 for Course 1MS041\n",
    "Make     sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline     and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 1\n",
    "Maximum Points = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "1"
   },
   "source": [
    "\n",
    "Using the steps in the Sample Exam Problem 1 with Solution in notebook `09.ipynb`, derive the maximum likelihood estimate for $n$ IID samples from a random variable with the following probability density function:\n",
    "$$\n",
    "f(x; \\lambda) = \\frac{1}{24} \\lambda^5 x^4 \\exp(-\\lambda x), \\qquad \\text{ where, } \\lambda>0, x > 0\n",
    "$$\n",
    "\n",
    "You can solve the MLe by hand (using pencil paper or using key-strokes). Present your solution as the return value of a function called `def MLeForAssignment3Problem1(x)`, where `x` is a list of $n$ input data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "1"
   },
   "outputs": [],
   "source": [
    "# do not change the name of the function, just replace XXX with the appropriate expressions for the MLe\n",
    "def MLeForAssignment3Problem1(x):\n",
    "    '''write comment of what this function does'''\n",
    "    tn=sum(x) \n",
    "    n = len(x)\n",
    "    return 5*n/tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 2\n",
    "Maximum Points = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "2"
   },
   "source": [
    "\n",
    "Joshua Fenemore collected data in 2007 on waiting times at the Orbiter bus-stop close to University of Canterbury, Christchurch, New Zealand.\n",
    "The sampled waiting times at the bus-stop, i.e., the inter-arrival time between consecutive buses, were recored in units of nearest minute and are given in the list `sampleWaitingTimes` below.\n",
    "\n",
    "Your **task** is to assume that the inter-arrival time between Orbiter buses is independent and identically distributed according to $Exponential(\\lambda)$ random variable and write a generic function:\n",
    "\n",
    "- called `mleOfExponetialLambdaRVFromIIDSamples(samples)`,\n",
    "- where `samples` is a `list` of  data points assumed to be drawn from IID  $Exponential(\\lambda)$ random variable,\n",
    "- such that, the function returns the maximum likelihood estimate or MLe $\\widehat{\\lambda}_n$ of the unknown rate parameter $\\lambda$ \n",
    "- finally get the MLe for Joshua's data by calling your function on his samples as follows:\n",
    "  - `mleOfRateParameterForOrbiterWaitingTimes = mleOfExponetialLambdaRVFromIIDSamples(sampleWaitingTimes)`\n",
    "\n",
    "(NOTE: The MLe for this model was already derived \"above\", i.e., in `09.ipynb`, so you can directly use this expression to complete your task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "2"
   },
   "outputs": [],
   "source": [
    "# do not change the sampled data-points in sampleWaitingTimes\n",
    "sampleWaitingTimes=[8,3,7,18,18,3,7,9,9,25,0,0,25,6,10,0,10,8,16,9,1,5,16,6,4,1,3,21,0,28,3,8,6,6,11,\\\n",
    "                    8,10,15,0,8,7,11,10,9,12,13,8,10,11,8,7,11,5,9,11,14,13,5,8,9,12,10,13,6,11,13,0,\\\n",
    "                    0,11,1,9,5,14,16,2,10,21,1,14,2,10,24,6,1,14,14,0,14,4,11,15,0,10,2,13,2,22,10,5,\\\n",
    "                    6,13,1,13,10,11,4,7,9,12,8,16,15,14,5,10,12,9,8,0,5,13,13,6,8,4,13,15,7,11,6,23,1]\n",
    "# do not change the next line, but just replace XXX - 1 POINT\n",
    "# in the body of the function to complete your task\n",
    "def mleOfExponetialLambdaRVFromIIDSamples(samples):\n",
    "    '''XXX'''\n",
    "    tn = sum(samples)\n",
    "    n = len(samples)\n",
    "    return 5*n/tn\n",
    "\n",
    "# You should not change anything in the line below - 1 POINT\n",
    "mleOfRateParameterForOrbiterWaitingTimes = mleOfExponetialLambdaRVFromIIDSamples(sampleWaitingTimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 3\n",
    "Maximum Points = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "2"
   },
   "source": [
    "\n",
    "Use Bounded 1D Optimisation to find the maximum likelihood estimate for the IID $Bernoulli(\\theta)$ experiment using data in the array `dataSamples` below.\n",
    "\n",
    "HINT: First, Study the Solution to the **Sample Exam Problem 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hr/2t7hsj753qg3n1q7zbnr625m0000gn/T/ipykernel_27952/2353342343.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  return  np.sum(np.log(paramLam ** 2) + 0.5 * (dataSamplesCoinToss / paramLam)**2 - np.log(dataSamplesCoinToss))\n",
      "/Users/max/anaconda3/envs/deeplearning/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2305: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  r = (xf - nfc) * (fx - ffulc)\n",
      "/Users/max/anaconda3/envs/deeplearning/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2306: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  q = (xf - fulc) * (fx - fnfc)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " message: Solution found.\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: inf\n",
       "       x: 0.9899941047084844\n",
       "     nit: 25\n",
       "    nfev: 25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "# do not change next line - dataSamplesCoinToss is the sampled data-points\n",
    "dataSamplesCoinToss= np.array([0,0,1,1,1,1,1,0,0,1,1,0,0,1,1,0,0])\n",
    "\n",
    "# finding MLE for IID Bernoulli(theta) RV\n",
    "# do not Chnage the name of the next function - just replace XXX\n",
    "def negLogLklOBernoulliIIDSamples(paramLam):\n",
    "    '''XXX'''\n",
    "    if paramLam <= 0:\n",
    "        return np.inf\n",
    "    return  np.sum(np.log(paramLam ** 2) + 0.5 * (dataSamplesCoinToss / paramLam)**2 - np.log(dataSamplesCoinToss))\n",
    "\n",
    "theta_initial= 0.01\n",
    "\n",
    "# do NOT change the next two lines\n",
    "boundedBernoulliResult = optimize.minimize_scalar(negLogLklOBernoulliIIDSamples, theta_initial, \\\n",
    "                                                  bounds=(0.001, 0.99), method='bounded')\n",
    "boundedBernoulliResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 4\n",
    "Maximum Points = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "2"
   },
   "source": [
    "\n",
    "Use the **Multi-dimensional Constrained Optimisation** example above (in `09.ipynb`) to numerically find the MLe for the mean and variance parameter based on `normallySimulatedDataSamples`, an array obtained by a specific simulation of $30$ IID samples from the $Normal(10,2)$ random variable.\n",
    "\n",
    "Recall that $Normal(\\mu, \\sigma^2)$ RV has the probability density function given by:\n",
    "\n",
    "$$\n",
    "f(x ;\\mu, \\sigma) = \\displaystyle\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(\\frac{-1}{2\\sigma^2}(x-\\mu)^2\\right)\n",
    "$$\n",
    "\n",
    "The two parameters, $\\mu \\in \\mathbb{R} := (-\\infty,\\infty)$ and $\\sigma \\in (0,\\infty)$, are sometimes referred to as the location and scale parameters.\n",
    "\n",
    "You know that the log likelihood function for $n$ IID samples from a Normal RV with parameters $\\mu$ and $\\sigma$ simply follows from $\\sum_{i=1}^n \\log(f(x_i; \\mu,\\sigma))$, based on the IID assumption. \n",
    "\n",
    "NOTE: When setting bounding boxes for $\\mu$ and $\\sigma$ try to start with some guesses like $[-20,20]$ and $[0.1,5.0]$ and make it larger if the solution is at the boundary. Making the left bounding-point for $\\sigma$ too close to $0.0$ will cause division by zero Warnings. Other numerical instabilities can happen in such iterative numerical solutions to the MLe. You need to be patient and learn by trial-and-error. You will see the mathematical theory in more details in a future course in scientific computing/optimisation. So don't worry too much now except learning to use it for our problems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "4",
    "lx_problem_points": "2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 58.63138728248071\n",
       "        x: [ 9.269e+00  1.708e+00]\n",
       "      nit: 5\n",
       "      jac: [ 1.066e-05 -6.608e-05]\n",
       "     nfev: 27\n",
       "     njev: 9\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "# do NOT change the next three lines\n",
    "np.random.seed(123456) # set seed\n",
    "# simulate 30 IID samples drawn from Normal(10,2)RV\n",
    "normallySimulatedDataSamples = np.random.normal(10,2,30) \n",
    "\n",
    "# define the negative log likelihoo function you want to minimise by editing XXX\n",
    "def negLogLklOfIIDNormalSamples(parameters):\n",
    "    '''return the -log(likelihood) of normallySimulatedDataSamples with mean and var parameters'''\n",
    "    #mu_param=parameters[0]\n",
    "    #sigma_param=parameters[1]\n",
    "    mu_param = parameters[0]\n",
    "    sigma_param = parameters[1]\n",
    "    n = len(normallySimulatedDataSamples)\n",
    "    log_likelihood = -n * np.log(sigma_param * np.sqrt(2 * np.pi)) - np.sum((normallySimulatedDataSamples - mu_param) ** 2) / (2 * sigma_param ** 2)\n",
    "    return -log_likelihood\n",
    "\n",
    "\n",
    "# you should only change XXX below and not anything else\n",
    "parameter_bounding_box=((-20, 20), (0.1, 5.0)) # specify the constraints for each parameter - some guess work...\n",
    "initial_arguments = np.array([10, 2]) # point in 2D to initialise the minimize algorithm\n",
    "result_Ass3Prob4 = optimize.minimize(negLogLklOfIIDNormalSamples, initial_arguments, bounds=parameter_bounding_box) #,XXX)\n",
    "# call the minimize method above finally! you need to play a bit to get initial conditions and bounding box ok\n",
    "result_Ass3Prob4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 5\n",
    "Maximum Points = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "3"
   },
   "source": [
    "\n",
    "Obtain the 95% CI based on the asymptotic normality of the MLE for the mean paramater $\\lambda$ based on $n$ IID $Poisson(\\lambda^*)$ trials.\n",
    "\n",
    "Recall that a random variable $X \\sim Poisson(\\lambda)$ if its probability mass function is:\n",
    "\n",
    "$$\n",
    "f(x; \\lambda) = \\exp{(-\\lambda)} \\frac{\\lambda^x}{x!}, \\quad \\lambda > 0, \\quad x \\in \\{0,1,2,\\ldots\\}\n",
    "$$\n",
    "\n",
    "The MLe $\\widehat{\\lambda}_n = \\overline{x}_n$, the sample mean.\n",
    "\n",
    "Work out your answer and express it in the next cell by replacing `XXX`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "5",
    "lx_problem_points": "3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% CI for lambda based on IID Poisson(lambda) data in samplePoissonCounts = \n",
      "4.814824219053521 6.518509114279813\n"
     ]
    }
   ],
   "source": [
    "# Only replace the XXX below, do not change the function naemes or parameters\n",
    "import numpy as np\n",
    "samplePoissonCounts = np.array([0,5,11,5,6,8,9,0,1,14,2,4,4,11,2,12,10,5,6,1,7,9,8,0,5,7,11,6,0,1])\n",
    "\n",
    "def Assignment3Problem5(poissonSamples):\n",
    "    '''return the 95% confidence interval as a 2-tuple for the unknown parameter lambda* \n",
    "    from n IID Poisson(lambda*) trials in the input numpy array called samplePoissonCounts'''\n",
    "    # Calculating the sample mean\n",
    "    sample_mean = np.mean(poissonSamples)\n",
    "    \n",
    "    # Number of samples\n",
    "    n = len(poissonSamples)\n",
    "    \n",
    "    # Standard error of the mean\n",
    "    standard_error = np.sqrt(sample_mean / n)\n",
    "    \n",
    "    # Z-score for 95% CI\n",
    "    z_score = 1.96\n",
    "\n",
    "    # Calculating the lower and upper bounds of the 95% CI\n",
    "    lower95CI = sample_mean - z_score * standard_error\n",
    "    upper95CI = sample_mean + z_score * standard_error\n",
    "\n",
    "    return (lower95CI, upper95CI)\n",
    "\n",
    "# do NOT change anything below\n",
    "lowerCISampleExamProblem5,upperCISampleExamProblem5 = Assignment3Problem5(samplePoissonCounts)\n",
    "print (\"The 95% CI for lambda based on IID Poisson(lambda) data in samplePoissonCounts = \")\n",
    "print (lowerCISampleExamProblem5,upperCISampleExamProblem5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 6\n",
    "Maximum Points = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "3"
   },
   "source": [
    "\n",
    "For the Orbiter waiting time problem, assuming IID trials as follows: \n",
    "\n",
    "$$\\displaystyle{X_1,X_2,\\ldots,X_{n} \\overset{IID}{\\sim} Exponential(\\lambda^*)}$$\n",
    "\n",
    "Your task is to perform a Wald Test of size $\\alpha=0.05$ to try to reject the null hypothesis that the waiting time at the Orbiter bus-stop, i.e., the inter-arrival time between buses, is exactly $10$ minutes:\n",
    "\n",
    "$$\\displaystyle{H_0: \\lambda^*=\\lambda_0 \\quad \\text{ versus } \\quad H_1: \\lambda^* \\neq \\lambda_0, \\qquad \\text{ with }\\lambda_0=0.1}$$\n",
    "\n",
    "Show you work by replacing `XXX`s with the right expressions in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "6",
    "lx_problem_points": "3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mle lambdaHat =  0.11018363939899832\n",
      "Null value of lambda under H0 =  0.1\n",
      "estimated standard error 0.7899433024050229\n",
      "Wald statistic =  0.012891608002743618\n",
      "we fail to reject the null hypothesis that lambda0=0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sampleWaitingTimes = np.array([8,3,7,18,18,3,7,9,9,25,0,0,25,6,10,0,10,8,16,9,1,5,16,6,4,1,3,21,0,28,3,8,6,6,11,\\\n",
    "                               8,10,15,0,8,7,11,10,9,12,13,8,10,11,8,7,11,5,9,11,14,13,5,8,9,12,10,13,6,11,13,0,\\\n",
    "                               0,11,1,9,5,14,16,2,10,21,1,14,2,10,24,6,1,14,14,0,14,4,11,15,0,10,2,13,2,22,10,5,\\\n",
    "                               6,13,1,13,10,11,4,7,9,12,8,16,15,14,5,10,12,9,8,0,5,13,13,6,8,4,13,15,7,11,6,23,1])\n",
    "\n",
    "#test H0: lambda=0.1\n",
    "## STEP 1: get the MLE thetaHat\n",
    "lambdaHat= 1/np.mean(sampleWaitingTimes) # you need to use sampleWaitingTimes here!\n",
    "print (\"mle lambdaHat = \",lambdaHat)\n",
    "\n",
    "## STEP 2: get the NullLambda or lambda0\n",
    "NullLambda=0.1\n",
    "print (\"Null value of lambda under H0 = \", NullLambda)\n",
    "\n",
    "## STEP 3: get estimated standard error\n",
    "n = len(sampleWaitingTimes)\n",
    "seLambda= 1 / np.sqrt(n* lambdaHat**2) # see Sample Exam Problem 5 in 10.ipynb\n",
    "print (\"estimated standard error\",seLambda)\n",
    "\n",
    "# STEP 4: get Wald Statistic\n",
    "W= (lambdaHat - NullLambda)/seLambda\n",
    "print (\"Wald statistic = \",W)\n",
    "\n",
    "# STEP 5: conduct the size alpha=0.05 Wald test\n",
    "# do NOT change anything below\n",
    "rejectNullAssignment3Problem6 = abs(W) > 2.0 # alpha=0.05, so z_{alpha/2} =1.96 approx=2.0\n",
    "if (rejectNullAssignment3Problem6):\n",
    "    print (\"we reject the null hypothesis that lambda0=0.1\")\n",
    "else:\n",
    "    print (\"we fail to reject the null hypothesis that lambda0=0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lx_assignment_number": "3",
    "lx_problem_cell_type": "PROBLEM"
   },
   "source": [
    "---\n",
    "## Assignment 3, PROBLEM 7\n",
    "Maximum Points = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "7",
    "lx_problem_points": "2"
   },
   "source": [
    "\n",
    "Repeat the **three steps to perform a bootstrap** above as done in **Median of inter-EQ Time** example (notebook `11.ipynb`) to find the plug-in estimate and 95% CI for the *99-th Percentile of the inter-EQ time in minutes*.\n",
    "\n",
    "You just need to evaluate the next `REQUIRED-CELL` and replace `XXX` with the right expressions in the following cell.\n",
    "\n",
    "HINT: Median is the $50$-th Percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "7",
    "lx_problem_points": "2"
   },
   "outputs": [],
   "source": [
    "# REQUIRED-CELL\n",
    "\n",
    "# DO NOT MODIFY this cell \n",
    "# Evaluate this cell before trying this PROBLEM so that the required functions and variables are loaded\n",
    "import numpy as np\n",
    "import random\n",
    "## Be Patient! - This will take more time, about a minute or so\n",
    "###############################################################################################\n",
    "def getLonLatMagDepTimes(NZEQCsvFileName):\n",
    "    '''returns longitude, latitude, magnitude, depth and the origin time as unix time\n",
    "    for each observed earthquake in the csv filr named NZEQCsvFileName'''\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    from dateutil.parser import parse\n",
    "    import numpy as np\n",
    "    \n",
    "    with open(NZEQCsvFileName) as f:\n",
    "        reader = f.read() \n",
    "        dataList = reader.split('\\n')\n",
    "        \n",
    "    myDataAccumulatorList =[]\n",
    "    for data in dataList[1:-1]:\n",
    "        dataRow = data.split(',')\n",
    "        myTimeString = dataRow[2] # origintime\n",
    "        # let's also grab longitude, latitude, magnitude, depth\n",
    "        myDataString = [dataRow[4],dataRow[5],dataRow[6],dataRow[7]]\n",
    "        try: \n",
    "            myTypedTime = time.mktime(parse(myTimeString).timetuple())\n",
    "            myFloatData = [float(x) for x in myDataString]\n",
    "            myFloatData.append(myTypedTime) # append the processed timestamp\n",
    "            myDataAccumulatorList.append(myFloatData)\n",
    "        except TypeError as e: # error handling for type incompatibilities\n",
    "            print ('Error:  Error is ', e)\n",
    "    #return np.array(myDataAccumulatorList)\n",
    "    return myDataAccumulatorList\n",
    "\n",
    "myProcessedList = getLonLatMagDepTimes('starting_package/data/earthquakes.csv')\n",
    "\n",
    "def interQuakeTimes(quakeTimes):\n",
    "    '''Return a list inter-earthquake times in seconds from earthquake origin times\n",
    "    Date and time elements are expected to be in the 5th column of the array\n",
    "    Return a list of inter-quake times in seconds. NEEDS sorted quakeTimes Data'''\n",
    "    import numpy as np\n",
    "    retList = []\n",
    "    if len(quakeTimes) > 1:\n",
    "        retList = [quakeTimes[i]-quakeTimes[i-1] for i in range(1,len(quakeTimes))]\n",
    "    #return np.array(retList)\n",
    "    return retList\n",
    "\n",
    "def makeBootstrappedConfidenceIntervalOfStatisticT(dataset, statT, alpha, B=100):\n",
    "    '''make a bootstrapped 1-alpha confidence interval for ANY given statistic statT \n",
    "    from the dataset with B Bootstrap replications for 0 < alpha < 1, and \n",
    "    return lower CI, upper CI, bootstrapped_samples '''\n",
    "    n = len(dataset) # sample size of the original dataset\n",
    "    bootstrappedStatisticTs=[] # list to store the statistic T from each bootstrapped data\n",
    "    for b in range(B):\n",
    "        #sample indices at random between 0 and len(iQMinutes)-1 to make the bootstrapped dataset\n",
    "        randIndices=[random.randint(0,n-1) for i in range(n)] \n",
    "        bootstrappedDataset = dataset[randIndices] # resample with replacement from original dataset\n",
    "        bootstrappedStatisticT = statT(bootstrappedDataset)\n",
    "        bootstrappedStatisticTs.append(bootstrappedStatisticT)\n",
    "    # noe get the [2.5%, 97.5%] percentile-based CI\n",
    "    alpaAsPercentage=alpha*100.0\n",
    "    lowerBootstrap1MinusAlphaCIForStatisticT = np.percentile(bootstrappedStatisticTs,alpaAsPercentage/2)\n",
    "    upperBootstrap1MinusAlphaCIForStatisticT = np.percentile(bootstrappedStatisticTs,100-alpaAsPercentage/2)\n",
    "    return (lowerBootstrap1MinusAlphaCIForStatisticT,upperBootstrap1MinusAlphaCIForStatisticT,\\\n",
    "            np.array(bootstrappedStatisticTs))\n",
    "\n",
    "interQuakesSecs = interQuakeTimes(sorted([x[4] for x in myProcessedList]))\n",
    "iQMinutes = np.array(interQuakesSecs)/60.0\n",
    "###############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "3",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "7",
    "lx_problem_points": "2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Plug-in Point Estimate of the 99th-Percentile of inter-EQ Times =  123.1196666666668\n",
      "1-alpha Bootstrapped CI for the 99th-Percentile of inter-EQ Times =  (116.40185833333346, 129.941333333334)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Plug-in Point Estimate of the 99th-Percentile of inter-EQ Times = \u001b[39m\u001b[38;5;124m\"\u001b[39m, plugInEstimateOf99thPercentile)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1-alpha Bootstrapped CI for the 99th-Percentile of inter-EQ Times = \u001b[39m\u001b[38;5;124m\"\u001b[39m,(lowerCIT99P,upperCIT99P))\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m         for alpha = \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43malpha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m(digits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and bootstrap replicates = \u001b[39m\u001b[38;5;124m\"\u001b[39m,B)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'n'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "statT99thPercentile = lambda dataset : np.percentile(dataset,99) #statistic of interest\n",
    "alpha= 0.01\n",
    "B=1000 # number of bootstrap samples, reduce this to 100 while debuging and back to 1000 when done\n",
    "# plug-in point estimate of the 99th-Percentile of inter-EQ Times\n",
    "plugInEstimateOf99thPercentile = statT99thPercentile(iQMinutes)\n",
    "# get the bootstrapped samples and build 1-alpha confidence interval\n",
    "# do NOT change anything below\n",
    "lowerCIT99P,upperCIT99P,bootValuesT99P = \\\n",
    "                      makeBootstrappedConfidenceIntervalOfStatisticT(iQMinutes, statT99thPercentile, alpha, B)\n",
    "print (\"The Plug-in Point Estimate of the 99th-Percentile of inter-EQ Times = \", plugInEstimateOf99thPercentile)\n",
    "print (\"1-alpha Bootstrapped CI for the 99th-Percentile of inter-EQ Times = \",(lowerCIT99P,upperCIT99P))\n",
    "print (\"         for alpha = \",alpha.n(digits=2),\" and bootstrap replicates = \",B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "lx_assignment_number": "3",
  "lx_course_instance": "2020",
  "lx_course_name": "Introduction to Data Science: A Comp-Math-Stat Approach",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
